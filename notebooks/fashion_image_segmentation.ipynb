{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVm6nZgkQzaC"
      },
      "source": [
        "# Fashion Image segmentation with a U-Net-like architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "U-Net is a convolutional neural network that was developed for biomedical image segmentation at the Computer Science Department of the University of Freiburg, Germany. The network is based on the fully convolutional network and its architecture was modified and extended to work with fewer training images and to yield more precise segmentations.\n",
        "\n",
        "We will use the U-Net architecture to perform image segmentation on the [Fashionpedia](https://fashionpedia.github.io/home/) dataset. The dataset consists of 45,623 images in training set and 1158 for validation. There are a high variety of different sizes and aspect ratios in the dataset. The images are annotated with 46 different categories of fashion items. In order to include background detection, we will add an additional class to the dataset.\n",
        "\n",
        "The categories that we will use are:\n",
        "\n",
        "```yaml\n",
        "0 : shirt, blouse\n",
        "1 : top, t-shirt, sweatshirt\n",
        "2 : sweater\n",
        "3 : cardigan\n",
        "4 : jacket\n",
        "5 : vest\n",
        "6 : pants\n",
        "7 : shorts\n",
        "8 : skirt\n",
        "9 : coat\n",
        "10 : dress\n",
        "11 : jumpsuit\n",
        "12 : cape\n",
        "13 : glasses\n",
        "14 : hat\n",
        "15 : headband, head covering, hair accessory\n",
        "16 : tie\n",
        "17 : glove\n",
        "18 : watch\n",
        "19 : belt\n",
        "20 : leg warmer\n",
        "21 : tights, stockings\n",
        "22 : sock\n",
        "23 : shoe\n",
        "24 : bag, wallet\n",
        "25 : scarf\n",
        "26 : umbrella\n",
        "27 : hood\n",
        "28 : collar\n",
        "29 : lapel\n",
        "30 : epaulette\n",
        "31 : sleeve\n",
        "32 : pocket\n",
        "33 : neckline\n",
        "34 : buckle\n",
        "35 : zipper\n",
        "36 : applique\n",
        "37 : bead\n",
        "38 : bow\n",
        "39 : flower\n",
        "40 : fringe\n",
        "41 : ribbon\n",
        "42 : rivet\n",
        "43 : ruffle\n",
        "44 : sequin\n",
        "45 : tassel\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_rVMlfcQzaF"
      },
      "source": [
        "## Prepare paths of input images and target segmentation masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our file structure is mainly composed by the following structure:\n",
        "\n",
        "```bash\n",
        "datasets/\n",
        "├── fashion\n",
        "│   ├── annotations\n",
        "│   │   ├── train2020\n",
        "│   │   └── val2020\n",
        "│   ├── images\n",
        "│   │   ├── test2020\n",
        "│   │   ├── train2020\n",
        "│   │   └── val2020\n",
        "│   └── splits\n",
        "```\n",
        "\n",
        "The annotations were originally in JSON format and it was necessary to convert them to PNG masks. The following code was used to convert the JSON files to PNG masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PEV751Z_QzaF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 18:19:34.126194: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-03-26 18:19:34.150278: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-26 18:19:34.558966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of train samples: 45623\n",
            "Number of validation samples: 1158\n",
            "Number of test samples: 2042\n",
            "datasets/fashion/images/train2020/00000663ed1ff0c4e0132b9b9ac53f6e.jpg | datasets/fashion/annotations/train2020/00000663ed1ff0c4e0132b9b9ac53f6e_seg.png\n",
            "datasets/fashion/images/train2020/0000fe7c9191fba733c8a69cfaf962b7.jpg | datasets/fashion/annotations/train2020/0000fe7c9191fba733c8a69cfaf962b7_seg.png\n",
            "datasets/fashion/images/train2020/0002ec21ddb8477e98b2cbb87ea2e269.jpg | datasets/fashion/annotations/train2020/0002ec21ddb8477e98b2cbb87ea2e269_seg.png\n",
            "datasets/fashion/images/train2020/0002f5a0ebc162ecfb73e2c91e3b8f62.jpg | datasets/fashion/annotations/train2020/0002f5a0ebc162ecfb73e2c91e3b8f62_seg.png\n",
            "datasets/fashion/images/train2020/0004467156e47b0eb6de4aa6479cbd15.jpg | datasets/fashion/annotations/train2020/0004467156e47b0eb6de4aa6479cbd15_seg.png\n",
            "datasets/fashion/images/train2020/00048c3a2fb9c29340473c4cfc06424a.jpg | datasets/fashion/annotations/train2020/00048c3a2fb9c29340473c4cfc06424a_seg.png\n",
            "datasets/fashion/images/train2020/0006ea84499fd9a06fefbdf47a5eb4c0.jpg | datasets/fashion/annotations/train2020/0006ea84499fd9a06fefbdf47a5eb4c0_seg.png\n",
            "datasets/fashion/images/train2020/000775b6b5e27b011dc8bba2d7b85211.jpg | datasets/fashion/annotations/train2020/000775b6b5e27b011dc8bba2d7b85211_seg.png\n",
            "datasets/fashion/images/train2020/000aac3870ea7c59ca0333ffa5327323.jpg | datasets/fashion/annotations/train2020/000aac3870ea7c59ca0333ffa5327323_seg.png\n",
            "datasets/fashion/images/train2020/000b3a87508b0fa185fbd53ecbe2e4c6.jpg | datasets/fashion/annotations/train2020/000b3a87508b0fa185fbd53ecbe2e4c6_seg.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from IPython.display import Image, display\n",
        "from keras.utils import load_img\n",
        "from PIL import ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import io as tf_io\n",
        "\n",
        "\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "input_dir_train = \"datasets/fashion/images/train2020\"\n",
        "target_dir_train = \"datasets/fashion/annotations/train2020\"\n",
        "\n",
        "input_dir_val = \"datasets/fashion/images/val2020\"\n",
        "target_dir_val = \"datasets/fashion/annotations/val2020\"\n",
        "\n",
        "input_dir_test = \"datasets/fashion/images/test2020\"\n",
        "target_dir_test = \"datasets/fashion/annotations/test2020\"\n",
        "\n",
        "img_size = (256, 256)\n",
        "num_classes = 47\n",
        "batch_size = 32\n",
        "\n",
        "train_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir_train, fname)\n",
        "        for fname in os.listdir(input_dir_train)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir_val, fname)\n",
        "        for fname in os.listdir(input_dir_val)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir_test, fname)\n",
        "        for fname in os.listdir(input_dir_test)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_dir_train, fname)\n",
        "        for fname in os.listdir(target_dir_train)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_dir_val, fname)\n",
        "        for fname in os.listdir(target_dir_val)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Number of train samples:\", len(train_img_paths))\n",
        "print(\"Number of validation samples:\", len(val_img_paths))\n",
        "print(\"Number of test samples:\", len(test_img_paths))\n",
        "\n",
        "for input_path, target_path in zip(train_img_paths[:10], train_target_img_paths[:10]):\n",
        "    print(input_path, \"|\", target_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes:  47\n"
          ]
        }
      ],
      "source": [
        "COLORS = [\n",
        "    (0, 0, 0), (67, 161, 255), (167, 146, 11), (136, 126, 185), (44, 52, 10), (25, 33, 189), (73, 197, 184),\n",
        "    (20, 165, 16), (48, 37, 106), (98, 213, 120), (21, 104, 190), (191, 106, 197), (142, 63, 109), (155, 22, 122),\n",
        "    (43, 152, 125), (128, 89, 85), (11, 1, 133), (126, 45, 174), (32, 111, 29), (55, 31, 198), (70, 250, 116),\n",
        "    (216, 21, 138), (100, 0, 176), (171, 236, 47), (193, 137, 224), (36, 152, 214), (154, 165, 67), (73, 8, 110),\n",
        "    (67, 161, 255), (167, 146, 11), (136, 126, 185), (44, 52, 10), (25, 33, 189), (73, 197, 184), (20, 165, 16),\n",
        "    (48, 37, 106), (98, 213, 120), (21, 104, 190), (191, 106, 197), (142, 63, 109), (155, 22, 122), (43, 152, 125),\n",
        "    (128, 89, 85), (11, 1, 133), (126, 45, 174), (32, 111, 29), (55, 31, 198)\n",
        "]\n",
        "\n",
        "d_cats = {0: 'shirt, blouse', 1: 'top, t-shirt, sweatshirt', 2: 'sweater', 3: 'cardigan', 4: 'jacket', 5: 'vest', 6: 'pants', 7: 'shorts', \n",
        "          8: 'skirt', 9: 'coat', 10: 'dress', 11: 'jumpsuit', 12: 'cape', 13: 'glasses', 14: 'hat', 15: 'headband, head covering, hair accessory', \n",
        "          16: 'tie', 17: 'glove', 18: 'watch', 19: 'belt', 20: 'leg warmer', 21: 'tights, stockings', 22: 'sock', 23: 'shoe', 24: 'bag, wallet', \n",
        "          25: 'scarf', 26: 'umbrella', 27: 'hood', 28: 'collar', 29: 'lapel', 30: 'epaulette', 31: 'sleeve', 32: 'pocket', 33: 'neckline', \n",
        "          34: 'buckle', 35: 'zipper', 36: 'applique', 37: 'bead', 38: 'bow', 39: 'flower', 40: 'fringe', 41: 'ribbon', 42: 'rivet', 43: 'ruffle', \n",
        "          44: 'sequin', 45: 'tassel'}\n",
        "\n",
        "d_cats = {k+1:v for k, v in d_cats.items()}\n",
        "d_cats[0] = 'background'\n",
        "print(\"Number of classes: \", len(d_cats))\n",
        "\n",
        "\n",
        "def process_overlay_mask(mask):\n",
        "    mask = np.array(mask).astype(int)\n",
        "    # ax[i, 0].imshow(image, cmap='gray')\n",
        "        # For all the values in the mask, we will create a new mask with the same shape but with the color of the category\n",
        "    mask_color = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
        "    for i_ in range(mask.shape[0]):\n",
        "        for j in range(mask.shape[1]):\n",
        "            try:\n",
        "                mask_color[i_, j] = COLORS[mask[i_, j][0]]\n",
        "            except:\n",
        "                mask_color[i_, j] = COLORS[mask[i_, j]]\n",
        "    mask_color = mask_color.astype(np.uint8)\n",
        "    return mask_color"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0RpsWwdQzaF"
      },
      "source": [
        "## What does one input image and corresponding segmentation mask look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OuGLNydMQzaF"
      },
      "outputs": [],
      "source": [
        "# # Display input image #7\n",
        "# display(Image(filename=train_img_paths[9]))\n",
        "\n",
        "# # Display auto-contrast version of corresponding target (per-pixel categories)\n",
        "# img = ImageOps.autocontrast(load_img(train_target_img_paths[9]))\n",
        "# display(img)\n",
        "\n",
        "# n_imgs = 5\n",
        "# alpha = 0.6\n",
        "\n",
        "# fig, ax = plt.subplots(n_imgs, 3, figsize=(10, 20))\n",
        "# for i in range(n_imgs):\n",
        "#     image = np.array(load_img(train_img_paths[i]))\n",
        "#     mask = np.array(load_img(train_target_img_paths[i]))\n",
        "\n",
        "#     mask_color = process_overlay_mask(mask)\n",
        "    \n",
        "#     ax[i ,0].imshow(image)\n",
        "#     ax[i, 0].set_title(\"Original Image\")\n",
        "\n",
        "#     # Combine original image with colored mask\n",
        "#     image1 = cv2.addWeighted(image * 1.0, 1 - alpha, mask_color * 1.0, alpha, 0).astype(np.uint8)\n",
        "#     ax[i ,1].imshow(mask_color)\n",
        "#     ax[i, 1].set_title(\"Mask\")\n",
        "\n",
        "#     ax[i, 2].imshow(image1)\n",
        "#     ax[i, 2].set_title(\"Overlayed Mask on Image\")\n",
        "    \n",
        "#     # axis off for all subplots\n",
        "#     for j in range(3):\n",
        "#         ax[i, j].axis('off')\n",
        "\n",
        "    # plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgy_8HBCQzaF"
      },
      "source": [
        "## Prepare dataset to load & vectorize batches of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wDlgPG_zQzaF"
      },
      "outputs": [],
      "source": [
        "def get_dataset(\n",
        "    batch_size,\n",
        "    img_size,\n",
        "    input_img_paths,\n",
        "    target_img_paths,\n",
        "    max_dataset_len=None,\n",
        "):\n",
        "    \"\"\"Returns a TF Dataset.\"\"\"\n",
        "\n",
        "    def load_img_masks(input_img_path, target_img_path):\n",
        "        input_img = tf_io.read_file(input_img_path)\n",
        "        input_img = tf_io.decode_png(input_img, channels=3)\n",
        "        input_img = tf_image.resize(input_img, img_size)\n",
        "        input_img = tf_image.convert_image_dtype(input_img, \"float32\")\n",
        "\n",
        "        target_img = tf_io.read_file(target_img_path)\n",
        "        target_img = tf_io.decode_png(target_img, channels=1)\n",
        "        target_img = tf_image.resize(target_img, img_size, method=\"nearest\")\n",
        "        target_img = tf_image.convert_image_dtype(target_img, \"uint8\")\n",
        "\n",
        "        return input_img, target_img\n",
        "\n",
        "    # For faster debugging, limit the size of data\n",
        "    if max_dataset_len:\n",
        "        input_img_paths = input_img_paths[:max_dataset_len]\n",
        "        target_img_paths = target_img_paths[:max_dataset_len]\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((input_img_paths, target_img_paths))\n",
        "    dataset = dataset.map(load_img_masks, num_parallel_calls=tf_data.AUTOTUNE)\n",
        "    return dataset.batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihdyxT20QzaG"
      },
      "source": [
        "## Prepare U-Net Xception-style model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V8xScWpaQzaG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 18:19:39.341187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-03-26 18:19:39.358738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-03-26 18:19:39.358866: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-03-26 18:19:39.361351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-03-26 18:19:39.361541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-03-26 18:19:39.361633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-03-26 18:19:39.414565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-03-26 18:19:39.414660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-03-26 18:19:39.414712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-03-26 18:19:39.414763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1153 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 128, 256, 32  896         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 128, 256, 32  128        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 128, 256, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 128, 256, 32  0           ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d (SeparableCon  (None, 128, 256, 64  2400       ['activation_1[0][0]']           \n",
            " v2D)                           )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 256, 64  256        ['separable_conv2d[0][0]']       \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 256, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d_1 (SeparableC  (None, 128, 256, 64  4736       ['activation_2[0][0]']           \n",
            " onv2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 256, 64  256        ['separable_conv2d_1[0][0]']     \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 64, 128, 64)  0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 64, 128, 64)  2112        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 64, 128, 64)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 64, 128, 64)  0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " separable_conv2d_2 (SeparableC  (None, 64, 128, 128  8896       ['activation_3[0][0]']           \n",
            " onv2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 64, 128, 128  512        ['separable_conv2d_2[0][0]']     \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64, 128, 128  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d_3 (SeparableC  (None, 64, 128, 128  17664      ['activation_4[0][0]']           \n",
            " onv2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 128, 128  512        ['separable_conv2d_3[0][0]']     \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 32, 64, 128)  0          ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 64, 128)  8320        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 64, 128)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 64, 128)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_4 (SeparableC  (None, 32, 64, 256)  34176      ['activation_5[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 64, 256)  1024       ['separable_conv2d_4[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 64, 256)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_5 (SeparableC  (None, 32, 64, 256)  68096      ['activation_6[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 64, 256)  1024       ['separable_conv2d_5[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 16, 32, 256)  0          ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 32, 256)  33024       ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 32, 256)  0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 32, 256)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 16, 32, 256)  590080     ['activation_7[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 32, 256)  1024       ['conv2d_transpose[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 32, 256)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 16, 32, 256)  590080     ['activation_8[0][0]']           \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 32, 256)  1024       ['conv2d_transpose_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 32, 64, 256)  0          ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 32, 64, 256)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 64, 256)  65792       ['up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 32, 64, 256)  0           ['up_sampling2d[0][0]',          \n",
            "                                                                  'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 32, 64, 256)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 32, 64, 128)  295040     ['activation_9[0][0]']           \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 64, 128)  512        ['conv2d_transpose_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 64, 128)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 32, 64, 128)  147584     ['activation_10[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 64, 128)  512        ['conv2d_transpose_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 64, 128, 256  0          ['add_3[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 64, 128, 128  0          ['batch_normalization_10[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 128, 128  32896       ['up_sampling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 64, 128, 128  0           ['up_sampling2d_2[0][0]',        \n",
            "                                )                                 'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 64, 128, 128  0           ['add_4[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 64, 128, 64)  73792      ['activation_11[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 128, 64)  256        ['conv2d_transpose_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64, 128, 64)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, 64, 128, 64)  36928      ['activation_12[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 128, 64)  256        ['conv2d_transpose_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 128, 256, 12  0          ['add_4[0][0]']                  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 128, 256, 64  0          ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 256, 64  8256        ['up_sampling2d_5[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 128, 256, 64  0           ['up_sampling2d_4[0][0]',        \n",
            "                                )                                 'conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 128, 256, 64  0           ['add_5[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (None, 128, 256, 32  18464      ['activation_13[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128, 256, 32  128        ['conv2d_transpose_6[0][0]']     \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 128, 256, 32  0           ['batch_normalization_13[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (None, 128, 256, 32  9248       ['activation_14[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 256, 32  128        ['conv2d_transpose_7[0][0]']     \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, 256, 512, 64  0          ['add_5[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, 256, 512, 32  0          ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 256, 512, 32  2080        ['up_sampling2d_7[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 256, 512, 32  0           ['up_sampling2d_6[0][0]',        \n",
            "                                )                                 'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 256, 512, 47  13583       ['add_6[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,071,695\n",
            "Trainable params: 2,067,919\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (3,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Build model\n",
        "model = get_model(img_size, num_classes)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roDgwwe6QzaG"
      },
      "source": [
        "## Set aside a validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TF82_pu2QzaG"
      },
      "outputs": [],
      "source": [
        "# Instantiate dataset for each split\n",
        "# Limit input files in `max_dataset_len` for faster epoch training time.\n",
        "# Remove the `max_dataset_len` arg when running with full dataset.\n",
        "train_dataset = get_dataset(\n",
        "    batch_size,\n",
        "    img_size,\n",
        "    train_img_paths,\n",
        "    train_target_img_paths,\n",
        "    # max_dataset_len=1000,\n",
        ")\n",
        "valid_dataset = get_dataset(\n",
        "    batch_size, img_size, val_img_paths, val_target_img_paths\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsi_qWglQzaG"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As this is a classification problem, we will use the categorical crossentropy loss function. The Adam optimizer is used with a learning rate of 0.0001. The model will be trained for 5 epochs with a batch size of 32.\n",
        "\n",
        "Due to computational time and complexity, all the images have been resized to 256x256 pixels. This makes the model less accurate but it is a good starting point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yCzxgq3KQzaG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 18:19:51.944328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
            "2024-03-26 18:19:52.002676: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
            "2024-03-26 18:19:52.002701: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
            "2024-03-26 18:19:52.002772: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
            "Relying on driver to perform ptx compilation. \n",
            "Modify $PATH to customize ptxas location.\n",
            "This message will be only logged once.\n",
            "2024-03-26 18:19:52.195286: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 272.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-26 18:19:52.195317: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
            "2024-03-26 18:19:52.277340: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-26 18:19:52.277388: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-26 18:19:52.277397: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-26 18:19:52.277404: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-26 18:19:52.277411: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-26 18:19:52.277419: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-26 18:19:52.277428: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-26 18:19:52.277434: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-26 18:19:52.277441: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-26 18:20:02.278741: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 256.00MiB (rounded to 268435456)requested by op model/batch_normalization_1/FusedBatchNormV3\n",
            "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
            "Current allocation summary follows.\n",
            "Current allocation summary follows.\n",
            "2024-03-26 18:20:02.278818: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
            "2024-03-26 18:20:02.278841: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 152, Chunks in use: 152. 38.0KiB allocated for chunks. 38.0KiB in use in bin. 18.1KiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278856: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 51, Chunks in use: 50. 26.0KiB allocated for chunks. 25.5KiB in use in bin. 25.0KiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278869: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 53, Chunks in use: 53. 55.0KiB allocated for chunks. 55.0KiB in use in bin. 53.3KiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278882: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 10, Chunks in use: 10. 27.8KiB allocated for chunks. 27.8KiB in use in bin. 24.8KiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278894: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 6, Chunks in use: 6. 27.0KiB allocated for chunks. 27.0KiB in use in bin. 27.0KiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278907: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 12, Chunks in use: 12. 99.0KiB allocated for chunks. 99.0KiB in use in bin. 99.0KiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278919: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 3, Chunks in use: 3. 48.0KiB allocated for chunks. 48.0KiB in use in bin. 48.0KiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278933: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 15, Chunks in use: 15. 563.5KiB allocated for chunks. 563.5KiB in use in bin. 554.6KiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278946: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 6, Chunks in use: 6. 414.5KiB allocated for chunks. 414.5KiB in use in bin. 408.0KiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278959: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 12, Chunks in use: 12. 1.55MiB allocated for chunks. 1.55MiB in use in bin. 1.55MiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278971: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 9, Chunks in use: 9. 2.38MiB allocated for chunks. 2.38MiB in use in bin. 2.34MiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.278985: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 3, Chunks in use: 3. 1.72MiB allocated for chunks. 1.72MiB in use in bin. 1.69MiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.279004: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 3. 4.00MiB allocated for chunks. 4.00MiB in use in bin. 3.38MiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.279028: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 6, Chunks in use: 6. 13.50MiB allocated for chunks. 13.50MiB in use in bin. 13.50MiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.279049: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-03-26 18:20:02.279066: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-03-26 18:20:02.279077: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-03-26 18:20:02.279105: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 3, Chunks in use: 2. 132.00MiB allocated for chunks. 80.00MiB in use in bin. 80.00MiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.279124: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 64.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.279147: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 5, Chunks in use: 4. 677.15MiB allocated for chunks. 512.00MiB in use in bin. 512.00MiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.279170: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 256.00MiB allocated for chunks. 256.00MiB in use in bin. 256.00MiB client-requested in use in bin.\n",
            "2024-03-26 18:20:02.279189: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 256.00MiB was 256.00MiB, Chunk State: \n",
            "2024-03-26 18:20:02.279206: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 1209597952\n",
            "2024-03-26 18:20:02.279228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e000000 of size 1280 next 1\n",
            "2024-03-26 18:20:02.279244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e000500 of size 256 next 2\n",
            "2024-03-26 18:20:02.279259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e000600 of size 256 next 3\n",
            "2024-03-26 18:20:02.279267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e000700 of size 256 next 5\n",
            "2024-03-26 18:20:02.279275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e000800 of size 256 next 6\n",
            "2024-03-26 18:20:02.279283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e000900 of size 256 next 4\n",
            "2024-03-26 18:20:02.279291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e000a00 of size 256 next 7\n",
            "2024-03-26 18:20:02.279299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e000b00 of size 256 next 10\n",
            "2024-03-26 18:20:02.279307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 75422e000c00 of size 512 next 12\n",
            "2024-03-26 18:20:02.279315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e000e00 of size 256 next 13\n",
            "2024-03-26 18:20:02.279323: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e000f00 of size 256 next 14\n",
            "2024-03-26 18:20:02.279331: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001000 of size 256 next 16\n",
            "2024-03-26 18:20:02.279339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001100 of size 256 next 17\n",
            "2024-03-26 18:20:02.279347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001200 of size 256 next 20\n",
            "2024-03-26 18:20:02.279355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001300 of size 256 next 15\n",
            "2024-03-26 18:20:02.279363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001400 of size 256 next 18\n",
            "2024-03-26 18:20:02.279371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001500 of size 256 next 23\n",
            "2024-03-26 18:20:02.279378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001600 of size 256 next 24\n",
            "2024-03-26 18:20:02.279391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001700 of size 256 next 25\n",
            "2024-03-26 18:20:02.279405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001800 of size 256 next 26\n",
            "2024-03-26 18:20:02.279416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001900 of size 256 next 29\n",
            "2024-03-26 18:20:02.279428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001a00 of size 256 next 27\n",
            "2024-03-26 18:20:02.279441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001b00 of size 256 next 32\n",
            "2024-03-26 18:20:02.279458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001c00 of size 256 next 19\n",
            "2024-03-26 18:20:02.279473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e001d00 of size 2304 next 8\n",
            "2024-03-26 18:20:02.279487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e002600 of size 3584 next 9\n",
            "2024-03-26 18:20:02.279495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e003400 of size 256 next 28\n",
            "2024-03-26 18:20:02.279503: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e003500 of size 256 next 35\n",
            "2024-03-26 18:20:02.279511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e003600 of size 256 next 36\n",
            "2024-03-26 18:20:02.279519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e003700 of size 256 next 37\n",
            "2024-03-26 18:20:02.279528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e003800 of size 512 next 59\n",
            "2024-03-26 18:20:02.279536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e003a00 of size 512 next 60\n",
            "2024-03-26 18:20:02.279544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e003c00 of size 512 next 63\n",
            "2024-03-26 18:20:02.279552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e003e00 of size 256 next 65\n",
            "2024-03-26 18:20:02.279560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e003f00 of size 256 next 61\n",
            "2024-03-26 18:20:02.279568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e004000 of size 1536 next 31\n",
            "2024-03-26 18:20:02.279577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e004600 of size 2304 next 30\n",
            "2024-03-26 18:20:02.279586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e004f00 of size 1024 next 93\n",
            "2024-03-26 18:20:02.279596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e005300 of size 1024 next 96\n",
            "2024-03-26 18:20:02.279605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e005700 of size 1024 next 94\n",
            "2024-03-26 18:20:02.279614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e005b00 of size 1024 next 95\n",
            "2024-03-26 18:20:02.279622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e005f00 of size 1024 next 98\n",
            "2024-03-26 18:20:02.279631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e006300 of size 1024 next 99\n",
            "2024-03-26 18:20:02.279639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e006700 of size 1024 next 100\n",
            "2024-03-26 18:20:02.279647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e006b00 of size 256 next 101\n",
            "2024-03-26 18:20:02.279656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e006c00 of size 256 next 104\n",
            "2024-03-26 18:20:02.279664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e006d00 of size 512 next 107\n",
            "2024-03-26 18:20:02.279672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e006f00 of size 512 next 105\n",
            "2024-03-26 18:20:02.279681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e007100 of size 768 next 22\n",
            "2024-03-26 18:20:02.279691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e007400 of size 8192 next 21\n",
            "2024-03-26 18:20:02.279700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e009400 of size 256 next 41\n",
            "2024-03-26 18:20:02.279708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e009500 of size 256 next 38\n",
            "2024-03-26 18:20:02.279717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e009600 of size 512 next 46\n",
            "2024-03-26 18:20:02.279725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e009800 of size 512 next 42\n",
            "2024-03-26 18:20:02.279734: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e009a00 of size 512 next 45\n",
            "2024-03-26 18:20:02.279747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e009c00 of size 512 next 43\n",
            "2024-03-26 18:20:02.279760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e009e00 of size 2304 next 44\n",
            "2024-03-26 18:20:02.279775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00a700 of size 512 next 49\n",
            "2024-03-26 18:20:02.279784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00a900 of size 256 next 50\n",
            "2024-03-26 18:20:02.279792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00aa00 of size 256 next 51\n",
            "2024-03-26 18:20:02.279800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00ab00 of size 256 next 54\n",
            "2024-03-26 18:20:02.279808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00ac00 of size 256 next 52\n",
            "2024-03-26 18:20:02.279816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00ad00 of size 512 next 53\n",
            "2024-03-26 18:20:02.279824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00af00 of size 512 next 56\n",
            "2024-03-26 18:20:02.279832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00b100 of size 768 next 40\n",
            "2024-03-26 18:20:02.279840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00b400 of size 8192 next 39\n",
            "2024-03-26 18:20:02.279849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00d400 of size 4608 next 55\n",
            "2024-03-26 18:20:02.279858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00e600 of size 4608 next 66\n",
            "2024-03-26 18:20:02.279866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00f800 of size 1024 next 68\n",
            "2024-03-26 18:20:02.279874: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e00fc00 of size 1024 next 62\n",
            "2024-03-26 18:20:02.279882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e010000 of size 1024 next 67\n",
            "2024-03-26 18:20:02.279890: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e010400 of size 1024 next 71\n",
            "2024-03-26 18:20:02.279898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e010800 of size 256 next 72\n",
            "2024-03-26 18:20:02.279906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e010900 of size 256 next 73\n",
            "2024-03-26 18:20:02.279914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e010a00 of size 256 next 74\n",
            "2024-03-26 18:20:02.279922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e010b00 of size 256 next 75\n",
            "2024-03-26 18:20:02.279930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e010c00 of size 1024 next 78\n",
            "2024-03-26 18:20:02.279938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e011000 of size 1024 next 34\n",
            "2024-03-26 18:20:02.279947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e011400 of size 16384 next 33\n",
            "2024-03-26 18:20:02.279957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e015400 of size 16384 next 184\n",
            "2024-03-26 18:20:02.279965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e019400 of size 8192 next 188\n",
            "2024-03-26 18:20:02.279974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e01b400 of size 40960 next 48\n",
            "2024-03-26 18:20:02.279983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e025400 of size 32768 next 47\n",
            "2024-03-26 18:20:02.279992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e02d400 of size 32768 next 64\n",
            "2024-03-26 18:20:02.280000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e035400 of size 1024 next 79\n",
            "2024-03-26 18:20:02.280009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e035800 of size 1024 next 82\n",
            "2024-03-26 18:20:02.280017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e035c00 of size 1024 next 83\n",
            "2024-03-26 18:20:02.280026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e036000 of size 1024 next 86\n",
            "2024-03-26 18:20:02.280034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e036400 of size 256 next 84\n",
            "2024-03-26 18:20:02.280042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e036500 of size 256 next 85\n",
            "2024-03-26 18:20:02.280050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e036600 of size 1024 next 90\n",
            "2024-03-26 18:20:02.280058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e036a00 of size 1024 next 88\n",
            "2024-03-26 18:20:02.280066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e036e00 of size 1024 next 89\n",
            "2024-03-26 18:20:02.280074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e037200 of size 1536 next 77\n",
            "2024-03-26 18:20:02.280083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e037800 of size 9216 next 76\n",
            "2024-03-26 18:20:02.280092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e039c00 of size 512 next 106\n",
            "2024-03-26 18:20:02.280100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e039e00 of size 512 next 108\n",
            "2024-03-26 18:20:02.280108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03a000 of size 256 next 110\n",
            "2024-03-26 18:20:02.280117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03a100 of size 256 next 111\n",
            "2024-03-26 18:20:02.280125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03a200 of size 512 next 114\n",
            "2024-03-26 18:20:02.280133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03a400 of size 512 next 112\n",
            "2024-03-26 18:20:02.280141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03a600 of size 512 next 113\n",
            "2024-03-26 18:20:02.280149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03a800 of size 512 next 117\n",
            "2024-03-26 18:20:02.280157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03aa00 of size 512 next 118\n",
            "2024-03-26 18:20:02.280165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03ac00 of size 512 next 119\n",
            "2024-03-26 18:20:02.280173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03ae00 of size 256 next 120\n",
            "2024-03-26 18:20:02.280181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03af00 of size 256 next 121\n",
            "2024-03-26 18:20:02.280194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03b000 of size 256 next 125\n",
            "2024-03-26 18:20:02.280207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03b100 of size 256 next 123\n",
            "2024-03-26 18:20:02.280222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03b200 of size 256 next 124\n",
            "2024-03-26 18:20:02.280231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03b300 of size 256 next 127\n",
            "2024-03-26 18:20:02.280239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03b400 of size 256 next 128\n",
            "2024-03-26 18:20:02.280247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03b500 of size 256 next 129\n",
            "2024-03-26 18:20:02.280255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03b600 of size 256 next 130\n",
            "2024-03-26 18:20:02.280264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03b700 of size 256 next 131\n",
            "2024-03-26 18:20:02.280272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03b800 of size 256 next 132\n",
            "2024-03-26 18:20:02.280280: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03b900 of size 256 next 135\n",
            "2024-03-26 18:20:02.280288: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03ba00 of size 256 next 136\n",
            "2024-03-26 18:20:02.280296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03bb00 of size 256 next 137\n",
            "2024-03-26 18:20:02.280304: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03bc00 of size 256 next 140\n",
            "2024-03-26 18:20:02.280313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03bd00 of size 256 next 138\n",
            "2024-03-26 18:20:02.280321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03be00 of size 256 next 139\n",
            "2024-03-26 18:20:02.280329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03bf00 of size 256 next 142\n",
            "2024-03-26 18:20:02.280337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03c000 of size 256 next 143\n",
            "2024-03-26 18:20:02.280345: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03c100 of size 256 next 145\n",
            "2024-03-26 18:20:02.280353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03c200 of size 256 next 146\n",
            "2024-03-26 18:20:02.280362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03c300 of size 256 next 147\n",
            "2024-03-26 18:20:02.280370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03c400 of size 256 next 148\n",
            "2024-03-26 18:20:02.280378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03c500 of size 256 next 149\n",
            "2024-03-26 18:20:02.280386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03c600 of size 256 next 150\n",
            "2024-03-26 18:20:02.280394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03c700 of size 256 next 151\n",
            "2024-03-26 18:20:02.280402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03c800 of size 256 next 152\n",
            "2024-03-26 18:20:02.280411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03c900 of size 256 next 154\n",
            "2024-03-26 18:20:02.280419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03ca00 of size 256 next 155\n",
            "2024-03-26 18:20:02.280427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03cb00 of size 256 next 158\n",
            "2024-03-26 18:20:02.280435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03cc00 of size 256 next 156\n",
            "2024-03-26 18:20:02.280443: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03cd00 of size 256 next 157\n",
            "2024-03-26 18:20:02.280451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03ce00 of size 256 next 161\n",
            "2024-03-26 18:20:02.280459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03cf00 of size 256 next 162\n",
            "2024-03-26 18:20:02.280467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03d000 of size 256 next 164\n",
            "2024-03-26 18:20:02.280476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03d100 of size 256 next 165\n",
            "2024-03-26 18:20:02.280484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03d200 of size 256 next 166\n",
            "2024-03-26 18:20:02.280492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03d300 of size 256 next 58\n",
            "2024-03-26 18:20:02.280501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e03d400 of size 65536 next 57\n",
            "2024-03-26 18:20:02.280510: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e04d400 of size 32768 next 141\n",
            "2024-03-26 18:20:02.280518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e055400 of size 32768 next 198\n",
            "2024-03-26 18:20:02.280527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e05d400 of size 4608 next 200\n",
            "2024-03-26 18:20:02.280535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e05e600 of size 1024 next 202\n",
            "2024-03-26 18:20:02.280543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e05ea00 of size 1024 next 203\n",
            "2024-03-26 18:20:02.280552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e05ee00 of size 9216 next 204\n",
            "2024-03-26 18:20:02.280560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e061200 of size 1024 next 205\n",
            "2024-03-26 18:20:02.280568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e061600 of size 1024 next 206\n",
            "2024-03-26 18:20:02.280576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e061a00 of size 1024 next 207\n",
            "2024-03-26 18:20:02.280584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e061e00 of size 1024 next 208\n",
            "2024-03-26 18:20:02.280592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e062200 of size 1024 next 210\n",
            "2024-03-26 18:20:02.280600: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e062600 of size 1024 next 211\n",
            "2024-03-26 18:20:02.280609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e062a00 of size 1024 next 212\n",
            "2024-03-26 18:20:02.280616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e062e00 of size 1024 next 214\n",
            "2024-03-26 18:20:02.280625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e063200 of size 1024 next 215\n",
            "2024-03-26 18:20:02.280633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e063600 of size 1024 next 216\n",
            "2024-03-26 18:20:02.280641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e063a00 of size 1024 next 218\n",
            "2024-03-26 18:20:02.280649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e063e00 of size 512 next 220\n",
            "2024-03-26 18:20:02.280658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e064000 of size 512 next 221\n",
            "2024-03-26 18:20:02.280666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e064200 of size 512 next 222\n",
            "2024-03-26 18:20:02.280674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e064400 of size 512 next 223\n",
            "2024-03-26 18:20:02.280683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e064600 of size 512 next 224\n",
            "2024-03-26 18:20:02.280691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e064800 of size 512 next 225\n",
            "2024-03-26 18:20:02.280699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e064a00 of size 512 next 227\n",
            "2024-03-26 18:20:02.280707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e064c00 of size 256 next 229\n",
            "2024-03-26 18:20:02.280716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e064d00 of size 256 next 230\n",
            "2024-03-26 18:20:02.280730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e064e00 of size 256 next 231\n",
            "2024-03-26 18:20:02.280743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e064f00 of size 256 next 233\n",
            "2024-03-26 18:20:02.280755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e065000 of size 256 next 234\n",
            "2024-03-26 18:20:02.280763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e065100 of size 256 next 235\n",
            "2024-03-26 18:20:02.280772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e065200 of size 33280 next 122\n",
            "2024-03-26 18:20:02.280781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e06d400 of size 131072 next 70\n",
            "2024-03-26 18:20:02.280791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e08d400 of size 131072 next 69\n",
            "2024-03-26 18:20:02.280799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e0ad400 of size 131072 next 87\n",
            "2024-03-26 18:20:02.280808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e0cd400 of size 54272 next 163\n",
            "2024-03-26 18:20:02.280816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e0da800 of size 4608 next 194\n",
            "2024-03-26 18:20:02.280825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e0dba00 of size 72192 next 81\n",
            "2024-03-26 18:20:02.280834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e0ed400 of size 262144 next 80\n",
            "2024-03-26 18:20:02.280843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e12d400 of size 131072 next 201\n",
            "2024-03-26 18:20:02.280851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e14d400 of size 131072 next 103\n",
            "2024-03-26 18:20:02.280859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e16d400 of size 262144 next 102\n",
            "2024-03-26 18:20:02.280868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e1ad400 of size 294912 next 126\n",
            "2024-03-26 18:20:02.280877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e1f5400 of size 262144 next 217\n",
            "2024-03-26 18:20:02.280886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e235400 of size 622592 next 116\n",
            "2024-03-26 18:20:02.280895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e2cd400 of size 589824 next 115\n",
            "2024-03-26 18:20:02.280905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e35d400 of size 73728 next 144\n",
            "2024-03-26 18:20:02.280914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e36f400 of size 8192 next 180\n",
            "2024-03-26 18:20:02.280923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e371400 of size 256 next 185\n",
            "2024-03-26 18:20:02.280932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e371500 of size 256 next 186\n",
            "2024-03-26 18:20:02.280940: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e371600 of size 256 next 187\n",
            "2024-03-26 18:20:02.280949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e371700 of size 256 next 189\n",
            "2024-03-26 18:20:02.280957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e371800 of size 2304 next 190\n",
            "2024-03-26 18:20:02.280965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e372100 of size 512 next 191\n",
            "2024-03-26 18:20:02.280973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e372300 of size 512 next 192\n",
            "2024-03-26 18:20:02.280981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e372500 of size 512 next 193\n",
            "2024-03-26 18:20:02.280990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e372700 of size 512 next 195\n",
            "2024-03-26 18:20:02.280998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e372900 of size 512 next 196\n",
            "2024-03-26 18:20:02.281006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e372b00 of size 512 next 197\n",
            "2024-03-26 18:20:02.281014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e372d00 of size 512 next 199\n",
            "2024-03-26 18:20:02.281022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e372f00 of size 1280 next 160\n",
            "2024-03-26 18:20:02.281030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e373400 of size 8192 next 159\n",
            "2024-03-26 18:20:02.281040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e375400 of size 256 next 167\n",
            "2024-03-26 18:20:02.281054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e375500 of size 256 next 168\n",
            "2024-03-26 18:20:02.281068: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e375600 of size 256 next 169\n",
            "2024-03-26 18:20:02.281076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e375700 of size 256 next 170\n",
            "2024-03-26 18:20:02.281085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e375800 of size 256 next 171\n",
            "2024-03-26 18:20:02.281093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e375900 of size 256 next 172\n",
            "2024-03-26 18:20:02.281101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e375a00 of size 256 next 173\n",
            "2024-03-26 18:20:02.281140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e375b00 of size 256 next 174\n",
            "2024-03-26 18:20:02.281149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e375c00 of size 3584 next 175\n",
            "2024-03-26 18:20:02.281157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e376a00 of size 256 next 176\n",
            "2024-03-26 18:20:02.281165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e376b00 of size 256 next 177\n",
            "2024-03-26 18:20:02.281173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e376c00 of size 256 next 178\n",
            "2024-03-26 18:20:02.281182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e376d00 of size 1280 next 179\n",
            "2024-03-26 18:20:02.281190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e377200 of size 256 next 181\n",
            "2024-03-26 18:20:02.281198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e377300 of size 256 next 182\n",
            "2024-03-26 18:20:02.281206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e377400 of size 256 next 183\n",
            "2024-03-26 18:20:02.281215: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e377500 of size 3840 next 153\n",
            "2024-03-26 18:20:02.281225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e378400 of size 36864 next 134\n",
            "2024-03-26 18:20:02.281234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e381400 of size 147456 next 133\n",
            "2024-03-26 18:20:02.281244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e3a5400 of size 294912 next 109\n",
            "2024-03-26 18:20:02.281252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e3ed400 of size 1835008 next 92\n",
            "2024-03-26 18:20:02.281262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e5ad400 of size 2359296 next 91\n",
            "2024-03-26 18:20:02.281271: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422e7ed400 of size 2359296 next 97\n",
            "2024-03-26 18:20:02.281279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422ea2d400 of size 2359296 next 209\n",
            "2024-03-26 18:20:02.281287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422ec6d400 of size 2359296 next 213\n",
            "2024-03-26 18:20:02.281296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422eead400 of size 1179648 next 219\n",
            "2024-03-26 18:20:02.281305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422efcd400 of size 131072 next 226\n",
            "2024-03-26 18:20:02.281314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422efed400 of size 294912 next 228\n",
            "2024-03-26 18:20:02.281328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f035400 of size 147456 next 232\n",
            "2024-03-26 18:20:02.281342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f059400 of size 256 next 236\n",
            "2024-03-26 18:20:02.281356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f059500 of size 73728 next 237\n",
            "2024-03-26 18:20:02.281364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f06b500 of size 256 next 238\n",
            "2024-03-26 18:20:02.281372: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f06b600 of size 256 next 239\n",
            "2024-03-26 18:20:02.281381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f06b700 of size 256 next 240\n",
            "2024-03-26 18:20:02.281389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f06b800 of size 36864 next 241\n",
            "2024-03-26 18:20:02.281398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f074800 of size 256 next 242\n",
            "2024-03-26 18:20:02.281406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f074900 of size 256 next 243\n",
            "2024-03-26 18:20:02.281414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f074a00 of size 256 next 244\n",
            "2024-03-26 18:20:02.281422: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f074b00 of size 8192 next 245\n",
            "2024-03-26 18:20:02.281430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f076b00 of size 256 next 246\n",
            "2024-03-26 18:20:02.281439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f076c00 of size 54272 next 247\n",
            "2024-03-26 18:20:02.281447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f084000 of size 256 next 248\n",
            "2024-03-26 18:20:02.281455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f084100 of size 3584 next 249\n",
            "2024-03-26 18:20:02.281463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f084f00 of size 256 next 250\n",
            "2024-03-26 18:20:02.281472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f085000 of size 256 next 251\n",
            "2024-03-26 18:20:02.281480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f085100 of size 256 next 252\n",
            "2024-03-26 18:20:02.281488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f085200 of size 1280 next 253\n",
            "2024-03-26 18:20:02.281496: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f085700 of size 8192 next 254\n",
            "2024-03-26 18:20:02.281505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f087700 of size 256 next 255\n",
            "2024-03-26 18:20:02.281513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f087800 of size 256 next 256\n",
            "2024-03-26 18:20:02.281521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f087900 of size 256 next 257\n",
            "2024-03-26 18:20:02.281529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f087a00 of size 2304 next 258\n",
            "2024-03-26 18:20:02.281538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f088300 of size 16384 next 259\n",
            "2024-03-26 18:20:02.281546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f08c300 of size 256 next 260\n",
            "2024-03-26 18:20:02.281554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f08c400 of size 256 next 261\n",
            "2024-03-26 18:20:02.281562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f08c500 of size 256 next 262\n",
            "2024-03-26 18:20:02.281570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f08c600 of size 8192 next 263\n",
            "2024-03-26 18:20:02.281579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f08e600 of size 256 next 264\n",
            "2024-03-26 18:20:02.281587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f08e700 of size 2304 next 265\n",
            "2024-03-26 18:20:02.281595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f08f000 of size 32768 next 266\n",
            "2024-03-26 18:20:02.281603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f097000 of size 512 next 267\n",
            "2024-03-26 18:20:02.281611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f097200 of size 512 next 268\n",
            "2024-03-26 18:20:02.281619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f097400 of size 512 next 269\n",
            "2024-03-26 18:20:02.281628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f097600 of size 4608 next 270\n",
            "2024-03-26 18:20:02.281636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f098800 of size 65536 next 271\n",
            "2024-03-26 18:20:02.281644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0a8800 of size 512 next 272\n",
            "2024-03-26 18:20:02.281653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0a8a00 of size 512 next 273\n",
            "2024-03-26 18:20:02.281662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0a8c00 of size 512 next 274\n",
            "2024-03-26 18:20:02.281678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0a8e00 of size 32768 next 275\n",
            "2024-03-26 18:20:02.281694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0b0e00 of size 512 next 276\n",
            "2024-03-26 18:20:02.281704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0b1000 of size 4608 next 277\n",
            "2024-03-26 18:20:02.281712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0b2200 of size 131072 next 278\n",
            "2024-03-26 18:20:02.281721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0d2200 of size 1024 next 279\n",
            "2024-03-26 18:20:02.281729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0d2600 of size 1024 next 280\n",
            "2024-03-26 18:20:02.281738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0d2a00 of size 1024 next 281\n",
            "2024-03-26 18:20:02.281746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0d2e00 of size 9216 next 282\n",
            "2024-03-26 18:20:02.281755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f0d5200 of size 262144 next 283\n",
            "2024-03-26 18:20:02.281763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f115200 of size 1024 next 284\n",
            "2024-03-26 18:20:02.281772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f115600 of size 1024 next 285\n",
            "2024-03-26 18:20:02.281780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f115a00 of size 1024 next 286\n",
            "2024-03-26 18:20:02.281788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f115e00 of size 131072 next 287\n",
            "2024-03-26 18:20:02.281797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f135e00 of size 1024 next 288\n",
            "2024-03-26 18:20:02.281805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f136200 of size 2359296 next 289\n",
            "2024-03-26 18:20:02.281813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f376200 of size 1024 next 290\n",
            "2024-03-26 18:20:02.281821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f376600 of size 1024 next 291\n",
            "2024-03-26 18:20:02.281829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f376a00 of size 1024 next 292\n",
            "2024-03-26 18:20:02.281838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f376e00 of size 2359296 next 293\n",
            "2024-03-26 18:20:02.281846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f5b6e00 of size 1024 next 294\n",
            "2024-03-26 18:20:02.281854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f5b7200 of size 1024 next 295\n",
            "2024-03-26 18:20:02.281862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f5b7600 of size 1024 next 296\n",
            "2024-03-26 18:20:02.281871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f5b7a00 of size 262144 next 297\n",
            "2024-03-26 18:20:02.281879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f5f7a00 of size 1024 next 298\n",
            "2024-03-26 18:20:02.281892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f5f7e00 of size 1179648 next 299\n",
            "2024-03-26 18:20:02.281906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f717e00 of size 512 next 300\n",
            "2024-03-26 18:20:02.281920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f718000 of size 512 next 301\n",
            "2024-03-26 18:20:02.281929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f718200 of size 512 next 302\n",
            "2024-03-26 18:20:02.281937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f718400 of size 589824 next 303\n",
            "2024-03-26 18:20:02.281946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f7a8400 of size 512 next 304\n",
            "2024-03-26 18:20:02.281954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f7a8600 of size 512 next 305\n",
            "2024-03-26 18:20:02.281962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f7a8800 of size 512 next 306\n",
            "2024-03-26 18:20:02.281970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f7a8a00 of size 131072 next 307\n",
            "2024-03-26 18:20:02.281979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f7c8a00 of size 512 next 308\n",
            "2024-03-26 18:20:02.281988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f7c8c00 of size 294912 next 309\n",
            "2024-03-26 18:20:02.281996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f810c00 of size 256 next 310\n",
            "2024-03-26 18:20:02.282004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f810d00 of size 256 next 311\n",
            "2024-03-26 18:20:02.282012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f810e00 of size 256 next 312\n",
            "2024-03-26 18:20:02.282021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f810f00 of size 147456 next 313\n",
            "2024-03-26 18:20:02.282030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f834f00 of size 256 next 314\n",
            "2024-03-26 18:20:02.282038: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f835000 of size 256 next 315\n",
            "2024-03-26 18:20:02.282046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f835100 of size 256 next 316\n",
            "2024-03-26 18:20:02.282054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f835200 of size 32768 next 317\n",
            "2024-03-26 18:20:02.282062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f83d200 of size 256 next 318\n",
            "2024-03-26 18:20:02.282071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f83d300 of size 73728 next 319\n",
            "2024-03-26 18:20:02.282080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f84f300 of size 256 next 320\n",
            "2024-03-26 18:20:02.282094: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f84f400 of size 256 next 321\n",
            "2024-03-26 18:20:02.282107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f84f500 of size 256 next 322\n",
            "2024-03-26 18:20:02.282120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f84f600 of size 36864 next 323\n",
            "2024-03-26 18:20:02.282128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f858600 of size 256 next 324\n",
            "2024-03-26 18:20:02.282137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f858700 of size 256 next 325\n",
            "2024-03-26 18:20:02.282145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f858800 of size 256 next 326\n",
            "2024-03-26 18:20:02.282153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f858900 of size 8192 next 327\n",
            "2024-03-26 18:20:02.282161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f85a900 of size 256 next 328\n",
            "2024-03-26 18:20:02.282170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f85aa00 of size 54272 next 329\n",
            "2024-03-26 18:20:02.282178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f867e00 of size 256 next 330\n",
            "2024-03-26 18:20:02.282186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f867f00 of size 256 next 331\n",
            "2024-03-26 18:20:02.282194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f868000 of size 256 next 332\n",
            "2024-03-26 18:20:02.282202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f868100 of size 256 next 333\n",
            "2024-03-26 18:20:02.282210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f868200 of size 256 next 334\n",
            "2024-03-26 18:20:02.282218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f868300 of size 256 next 335\n",
            "2024-03-26 18:20:02.282227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f868400 of size 256 next 336\n",
            "2024-03-26 18:20:02.282235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f868500 of size 256 next 337\n",
            "2024-03-26 18:20:02.282243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f868600 of size 256 next 346\n",
            "2024-03-26 18:20:02.282251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f868700 of size 256 next 347\n",
            "2024-03-26 18:20:02.282259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75422f868800 of size 256 next 338\n",
            "2024-03-26 18:20:02.282269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 75422f868900 of size 54525184 next 339\n",
            "2024-03-26 18:20:02.282284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 754232c68600 of size 33554432 next 340\n",
            "2024-03-26 18:20:02.282302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 754234c68600 of size 256 next 341\n",
            "2024-03-26 18:20:02.282311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 754234c68700 of size 256 next 342\n",
            "2024-03-26 18:20:02.282320: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 754234c68800 of size 50331648 next 343\n",
            "2024-03-26 18:20:02.282329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 754237c68800 of size 134217728 next 344\n",
            "2024-03-26 18:20:02.282338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75423fc68800 of size 134217728 next 345\n",
            "2024-03-26 18:20:02.282347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 754247c68800 of size 134217728 next 11\n",
            "2024-03-26 18:20:02.282356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75424fc68800 of size 67108864 next 348\n",
            "2024-03-26 18:20:02.282365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 754253c68800 of size 134217728 next 349\n",
            "2024-03-26 18:20:02.282374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 75425bc68800 of size 268435456 next 350\n",
            "2024-03-26 18:20:02.282384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 75426bc68800 of size 173176832 next 18446744073709551615\n",
            "2024-03-26 18:20:02.282392: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
            "2024-03-26 18:20:02.282406: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 152 Chunks of size 256 totalling 38.0KiB\n",
            "2024-03-26 18:20:02.282416: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 48 Chunks of size 512 totalling 24.0KiB\n",
            "2024-03-26 18:20:02.282427: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 768 totalling 1.5KiB\n",
            "2024-03-26 18:20:02.282443: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 47 Chunks of size 1024 totalling 47.0KiB\n",
            "2024-03-26 18:20:02.282460: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 1280 totalling 5.0KiB\n",
            "2024-03-26 18:20:02.282470: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1536 totalling 3.0KiB\n",
            "2024-03-26 18:20:02.282479: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 2304 totalling 13.5KiB\n",
            "2024-03-26 18:20:02.282489: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 3584 totalling 10.5KiB\n",
            "2024-03-26 18:20:02.282499: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3840 totalling 3.8KiB\n",
            "2024-03-26 18:20:02.282509: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 4608 totalling 27.0KiB\n",
            "2024-03-26 18:20:02.282519: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 9 Chunks of size 8192 totalling 72.0KiB\n",
            "2024-03-26 18:20:02.282528: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 9216 totalling 27.0KiB\n",
            "2024-03-26 18:20:02.282538: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 16384 totalling 48.0KiB\n",
            "2024-03-26 18:20:02.282548: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 32768 totalling 224.0KiB\n",
            "2024-03-26 18:20:02.282557: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33280 totalling 32.5KiB\n",
            "2024-03-26 18:20:02.282567: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 36864 totalling 108.0KiB\n",
            "2024-03-26 18:20:02.282580: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 40960 totalling 40.0KiB\n",
            "2024-03-26 18:20:02.282597: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 54272 totalling 159.0KiB\n",
            "2024-03-26 18:20:02.282611: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 65536 totalling 128.0KiB\n",
            "2024-03-26 18:20:02.282622: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 72192 totalling 70.5KiB\n",
            "2024-03-26 18:20:02.282631: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 73728 totalling 216.0KiB\n",
            "2024-03-26 18:20:02.282642: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 9 Chunks of size 131072 totalling 1.12MiB\n",
            "2024-03-26 18:20:02.282652: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 147456 totalling 432.0KiB\n",
            "2024-03-26 18:20:02.282661: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 262144 totalling 1.25MiB\n",
            "2024-03-26 18:20:02.282671: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 294912 totalling 1.12MiB\n",
            "2024-03-26 18:20:02.282681: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 589824 totalling 1.12MiB\n",
            "2024-03-26 18:20:02.282690: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 622592 totalling 608.0KiB\n",
            "2024-03-26 18:20:02.282700: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1179648 totalling 2.25MiB\n",
            "2024-03-26 18:20:02.282714: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1835008 totalling 1.75MiB\n",
            "2024-03-26 18:20:02.282731: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 2359296 totalling 13.50MiB\n",
            "2024-03-26 18:20:02.282742: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33554432 totalling 32.00MiB\n",
            "2024-03-26 18:20:02.282752: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 50331648 totalling 48.00MiB\n",
            "2024-03-26 18:20:02.282762: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 67108864 totalling 64.00MiB\n",
            "2024-03-26 18:20:02.282772: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 134217728 totalling 512.00MiB\n",
            "2024-03-26 18:20:02.282782: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 268435456 totalling 256.00MiB\n",
            "2024-03-26 18:20:02.282793: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 936.41MiB\n",
            "2024-03-26 18:20:02.282803: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 1209597952 memory_limit_: 1209597952 available bytes: 0 curr_region_allocation_bytes_: 2419195904\n",
            "2024-03-26 18:20:02.282823: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
            "Limit:                      1209597952\n",
            "InUse:                       981895424\n",
            "MaxInUse:                   1155080448\n",
            "NumAllocs:                         610\n",
            "MaxAllocSize:                285237504\n",
            "Reserved:                            0\n",
            "PeakReserved:                        0\n",
            "LargestFreeBlock:                    0\n",
            "\n",
            "2024-03-26 18:20:02.282858: W tensorflow/tsl/framework/bfc_allocator.cc:497] ***___********************************************************************************______________\n",
            "2024-03-26 18:20:02.282901: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at fused_batch_norm_op.cc:1565 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,64,128,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node 'model/batch_normalization_1/FusedBatchNormV3' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/alberto/.local/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/home/alberto/.local/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n      await self.process_one()\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n      await dispatch(*args)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n      reply_content = await reply_content\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n      result = self._run_cell(\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n      result = runner(coro)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_249577/3634470714.py\", line 14, in <module>\n      history = model.fit(\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/layers/normalization/batch_normalization.py\", line 922, in call\n      outputs = self._fused_batch_norm(\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/layers/normalization/batch_normalization.py\", line 688, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/layers/normalization/batch_normalization.py\", line 662, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model/batch_normalization_1/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,64,128,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/batch_normalization_1/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5493]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train the model, doing validation at the end of each epoch.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/batch_normalization_1/FusedBatchNormV3' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/alberto/.local/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/home/alberto/.local/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n      await self.process_one()\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n      await dispatch(*args)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n      reply_content = await reply_content\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/home/alberto/.local/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n      result = self._run_cell(\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n      result = runner(coro)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/alberto/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_249577/3634470714.py\", line 14, in <module>\n      history = model.fit(\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/layers/normalization/batch_normalization.py\", line 922, in call\n      outputs = self._fused_batch_norm(\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/layers/normalization/batch_normalization.py\", line 688, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"/home/alberto/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/layers/normalization/batch_normalization.py\", line 662, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model/batch_normalization_1/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,64,128,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/batch_normalization_1/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5493]"
          ]
        }
      ],
      "source": [
        "# Configure the model for training.\n",
        "# We use the \"sparse\" version of categorical_crossentropy\n",
        "# because our target data is integers.\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-4), loss=\"sparse_categorical_crossentropy\"\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"fashion_256x512.keras\", save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch.\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot history\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
        "# ax.plot(history.history[\"loss\"], label=\"train\")\n",
        "# ax.plot(history.history[\"val_loss\"], label=\"validation\")\n",
        "\n",
        "# # ax[1].plot(history.history[\"accuracy\"], label=\"train\")\n",
        "# # ax[1].plot(history.history[\"val_accuracy\"], label=\"validation\")\n",
        "\n",
        "# ax.set_xlabel(\"Epoch\")\n",
        "# # ax[1].set_xlabel(\"Epoch\")\n",
        "\n",
        "\n",
        "# ax.set_ylabel(\"Loss\")\n",
        "# # ax[1].set_ylabel(\"Mean IoU\")\n",
        "\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As it can be seen from previous loss values, the model could still be improved by increasing the number of epochs. However, the training time is too high for the kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEKK4qx4QzaG"
      },
      "source": [
        "## Visualize predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to better visualize the predictions, we will use some auxiliary functions to plot the images and masks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"fashion_256.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# val_dataset_examples = get_dataset(\n",
        "#                                         batch_size, img_size, val_img_paths[:4], val_target_img_paths[:4]\n",
        "#                                     )\n",
        "\n",
        "# fig, ax = plt.subplots(4, 4, figsize=(15, 20))\n",
        "# alpha = 0.5\n",
        "# i = 0\n",
        "# for img_batch, mask_batch in val_dataset_examples:\n",
        "#     for image, mask in zip(img_batch, mask_batch):\n",
        "#         image = np.array(image).astype(int)\n",
        "\n",
        "#         mask_color = process_overlay_mask(mask)\n",
        "\n",
        "#         # Combine original image with colored mask\n",
        "#         image1 = cv2.addWeighted(image * 1.0, 1 - alpha, mask_color * 1.0, alpha, 0).astype(np.uint8)\n",
        "#         ax[i ,0].imshow(image1)\n",
        "\n",
        "#         ax[i, 1].imshow(mask_color)\n",
        "\n",
        "#         pred_mask = model.predict(np.array([image]))\n",
        "#         pred_mask = np.argmax(pred_mask[0], axis=-1)\n",
        "#         pred_mask = process_overlay_mask(pred_mask)\n",
        "#         ax[i, 2].imshow(pred_mask)\n",
        "\n",
        "#         pred_mask = cv2.addWeighted(image * 1.0, 1 - alpha, pred_mask * 1.0, alpha, 0).astype(np.uint8)\n",
        "\n",
        "#         ax[i, 3].imshow(pred_mask)\n",
        "#         # plt.show()\n",
        "\n",
        "#         for j in range(4):\n",
        "#             ax[i, j].axis('off')\n",
        "            \n",
        "#         i += 1\n",
        "\n",
        "# ax[0, 0].set_title(\"Original Image with True Mask\")\n",
        "# ax[0, 1].set_title(\"True Mask\")\n",
        "# ax[0, 2].set_title(\"Predicted Mask\")\n",
        "# ax[0, 3].set_title(\"Original Image with Predicted Mask\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Validation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intersection over Union (IoU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This metric measures the overlap between predicted predicted segmentation map and the real one, with scores ranging from 0 to 1. The higher the score, the better the model is at predicting the correct segmentation map.\n",
        "\n",
        "$$\n",
        "IoU = \\frac{TP}{TP + FP + FN}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:42<00:00,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Validation IOU 0.19472773 +- 0.09439706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def get_iou(dataset, model):    \n",
        "    # Calculate the mean IoU\n",
        "    iou = []\n",
        "\n",
        "    for img_batch, mask_batch in tqdm(dataset):\n",
        "        for image, mask in zip(img_batch, mask_batch):\n",
        "            pred_mask = model.predict(np.array([image]), verbose=0)\n",
        "            pred_mask = np.argmax(pred_mask[0], axis=-1)\n",
        "            m = tf.keras.metrics.MeanIoU(num_classes=47)\n",
        "            m.update_state(mask, pred_mask)\n",
        "            iou.append(m.result().numpy())\n",
        "\n",
        "    return iou\n",
        "\n",
        "iou = get_iou(valid_dataset, model)\n",
        "print(\"\\n\\n\")\n",
        "print(\"Validation IOU\", np.mean(iou), \"+-\", np.std(iou))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get the center of the objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output of the model has a layer for each class. We will use the output of the model to get the center of the objects.\n",
        "\n",
        "The center has been computed as the mean of the x and y coordinates of the mask.\n",
        "\n",
        "In addition to this, a confidence threshold of 0.4 has been used to filter those predictions with a low confidence and avoid sparse false positives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # pred_number = 5\n",
        "# conf_thresh = 0.6\n",
        "# url = '/home/alberto/Descargas/fernando.jpeg'\n",
        "\n",
        "\n",
        "# for pn in range(6):\n",
        "#     if pn < 5:\n",
        "#         image = np.array(load_img(train_img_paths[pn]).resize((256, 256)))\n",
        "#     else:\n",
        "#         image = np.array(load_img(url).resize((256, 256)))\n",
        "        \n",
        "#     pred_mask = model.predict(np.array([image]))\n",
        "\n",
        "#     pred_mask_max = np.max(pred_mask[0], axis=-1)\n",
        "#     pred_mask = np.argmax(pred_mask[0], axis=-1)\n",
        "\n",
        "#     pred_mask = np.where(pred_mask_max > 0.4, pred_mask, 0)\n",
        "\n",
        "\n",
        "#     # for each of the non-zero classes, calculate the center\n",
        "#     d_centers = {}\n",
        "#     for i in np.unique(pred_mask):\n",
        "#         if i == 0:\n",
        "#             continue\n",
        "\n",
        "#         binary_mask = pred_mask == i\n",
        "#         if not mask.any():\n",
        "#             continue\n",
        "#         # Assume binary_mask is a 2D numpy array with dtype bool\n",
        "#         centroid = np.mean(np.argwhere(binary_mask),axis=0)\n",
        "#         centroid_x, centroid_y = int(centroid[1]), int(centroid[0])\n",
        "\n",
        "#         d_centers[d_cats[i]] = (centroid_x, centroid_y)\n",
        "\n",
        "#     # plot the centers\n",
        "\n",
        "#     fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
        "#     for (i, (center_x, center_y)) in d_centers.items():\n",
        "#         n_class = list(d_cats.keys())[list(d_cats.values()).index(i)]\n",
        "#         plt.plot(center_x, center_y*0.9, 'o', markersize=10, color=np.array(COLORS[n_class]) / 255, markeredgecolor='black')\n",
        "#         ax.annotate(f\"Class {i}\", (center_x, center_y), fontsize=12, ha='center', va='center', color = np.array(COLORS[n_class]) / 255)\n",
        "\n",
        "\n",
        "\n",
        "#     pred_mask_ = process_overlay_mask(pred_mask)\n",
        "\n",
        "#     image_ = cv2.addWeighted(image * 1.0, 1 - alpha, pred_mask_ * 1.0, alpha, 0).astype(np.uint8)\n",
        "#     ax.imshow(image_)\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "oxford_pets_image_segmentation",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.11.5 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
