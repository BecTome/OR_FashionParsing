{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchvision.datasets import VisionDataset\n",
    "from PIL import Image\n",
    "import csv\n",
    "\n",
    "\n",
    "def create_palette(csv_filepath):\n",
    "    color_to_class = {}\n",
    "    with open(csv_filepath, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for idx, row in enumerate(reader):\n",
    "            r, g, b = int(row['r']), int(row['g']), int(row['b'])\n",
    "            color_to_class[(r, g, b)] = idx\n",
    "    return color_to_class\n",
    "\n",
    "class CamVid(VisionDataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 img_folder,\n",
    "                 mask_folder,\n",
    "                 transform=None,\n",
    "                 target_transform=None):\n",
    "        super().__init__(\n",
    "            root, transform=transform, target_transform=target_transform)\n",
    "        self.img_folder = img_folder\n",
    "        self.mask_folder = mask_folder\n",
    "        self.images = list(\n",
    "            sorted(os.listdir(os.path.join(self.root, img_folder))))\n",
    "        self.masks = list(\n",
    "            sorted(os.listdir(os.path.join(self.root, mask_folder))))\n",
    "        self.color_to_class = create_palette(\n",
    "            os.path.join(self.root, 'class_dict.csv'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root, self.img_folder, self.images[index])\n",
    "        mask_path = os.path.join(self.root, self.mask_folder,\n",
    "                                 self.masks[index])\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('RGB')  # Convert to RGB\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Convert the RGB values to class indices\n",
    "        mask = np.array(mask)\n",
    "        mask = mask[:, :, 0] * 65536 + mask[:, :, 1] * 256 + mask[:, :, 2]\n",
    "        labels = np.zeros_like(mask, dtype=np.int64)\n",
    "        for color, class_index in self.color_to_class.items():\n",
    "            rgb = color[0] * 65536 + color[1] * 256 + color[2]\n",
    "            labels[mask == rgb] = class_index\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            labels = self.target_transform(labels)\n",
    "        data_samples = dict(\n",
    "            labels=labels, img_path=img_path, mask_path=mask_path)\n",
    "        return img, data_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "norm_cfg = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize(**norm_cfg)])\n",
    "\n",
    "target_transform = transforms.Lambda(\n",
    "        lambda x: torch.tensor(np.array(x), dtype=torch.long))\n",
    "\n",
    "train_set = CamVid(\n",
    "    'data/CamVid',\n",
    "    img_folder='train',\n",
    "    mask_folder='train_labels',\n",
    "    transform=transform,\n",
    "    target_transform=target_transform)\n",
    "\n",
    "valid_set = CamVid(\n",
    "    'data/CamVid',\n",
    "    img_folder='val',\n",
    "    mask_folder='val_labels',\n",
    "    transform=transform,\n",
    "    target_transform=target_transform)\n",
    "\n",
    "train_dataloader = dict(\n",
    "    batch_size=3,\n",
    "    dataset=train_set,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
    "    collate_fn=dict(type='default_collate'))\n",
    "\n",
    "val_dataloader = dict(\n",
    "    batch_size=3,\n",
    "    dataset=valid_set,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    collate_fn=dict(type='default_collate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5022,  0.5022,  0.4337,  ..., -1.6555, -1.6727, -1.7069],\n",
       "          [ 0.4337,  0.5022,  0.4679,  ..., -1.6555, -1.6727, -1.7069],\n",
       "          [ 0.5364,  0.5707,  0.5364,  ..., -1.6555, -1.6727, -1.7069],\n",
       "          ...,\n",
       "          [-1.8268, -1.8610, -1.8953,  ..., -1.6727, -1.6727, -1.7069],\n",
       "          [-1.8610, -1.8782, -1.9124,  ..., -1.6898, -1.6555, -1.6898],\n",
       "          [-1.8782, -1.9295, -1.9295,  ..., -1.7412, -1.7240, -1.7583]],\n",
       " \n",
       "         [[ 1.0980,  1.0980,  1.0455,  ..., -1.4930, -1.5630, -1.5980],\n",
       "          [ 1.0280,  1.0980,  1.0805,  ..., -1.4930, -1.5630, -1.5980],\n",
       "          [ 1.1331,  1.1681,  1.1681,  ..., -1.4930, -1.5630, -1.5980],\n",
       "          ...,\n",
       "          [-1.7381, -1.7731, -1.8081,  ..., -1.4055, -1.4405, -1.4755],\n",
       "          [-1.7556, -1.7731, -1.8081,  ..., -1.4230, -1.4230, -1.4580],\n",
       "          [-1.7731, -1.8256, -1.8256,  ..., -1.4755, -1.4930, -1.5280]],\n",
       " \n",
       "         [[ 1.4374,  1.4374,  1.4200,  ..., -1.3164, -1.3687, -1.4036],\n",
       "          [ 1.3677,  1.4374,  1.4548,  ..., -1.3164, -1.3339, -1.3687],\n",
       "          [ 1.4722,  1.5071,  1.4897,  ..., -1.2816, -1.3339, -1.3687],\n",
       "          ...,\n",
       "          [-1.4733, -1.5081, -1.5430,  ..., -1.0898, -1.1073, -1.1421],\n",
       "          [-1.5256, -1.5430, -1.5779,  ..., -1.1421, -1.1247, -1.1596],\n",
       "          [-1.5430, -1.5953, -1.5953,  ..., -1.1944, -1.1944, -1.2293]]]),\n",
       " {'labels': tensor([[21, 21, 21,  ..., 26, 26, 26],\n",
       "          [21, 21, 21,  ..., 26, 26, 26],\n",
       "          [21, 21, 21,  ..., 26, 26, 26],\n",
       "          ...,\n",
       "          [19, 19, 19,  ..., 30, 30, 30],\n",
       "          [19, 19, 19,  ..., 30, 30, 30],\n",
       "          [19, 19, 19,  ..., 30, 30, 30]]),\n",
       "  'img_path': 'data/CamVid/train/0001TP_009210.png',\n",
       "  'mask_path': 'data/CamVid/train_labels/0001TP_009210_L.png'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.model import BaseModel\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MMDeeplabV3(BaseModel):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.deeplab = deeplabv3_resnet50(num_classes=num_classes)\n",
    "\n",
    "    def forward(self, imgs, data_samples=None, mode='tensor'):\n",
    "        x = self.deeplab(imgs)['out']\n",
    "        if mode == 'loss':\n",
    "            return {'loss': F.cross_entropy(x, data_samples['labels'])}\n",
    "        elif mode == 'predict':\n",
    "            return x, data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.evaluator import BaseMetric\n",
    "\n",
    "class IoU(BaseMetric):\n",
    "\n",
    "    def process(self, data_batch, data_samples):\n",
    "        preds, labels = data_samples[0], data_samples[1]['labels']\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        intersect = (labels == preds).sum()\n",
    "        union = (torch.logical_or(preds, labels)).sum()\n",
    "        iou = (intersect / union).cpu()\n",
    "        self.results.append(\n",
    "            dict(batch_size=len(labels), iou=iou * len(labels)))\n",
    "\n",
    "    def compute_metrics(self, results):\n",
    "        total_iou = sum(result['iou'] for result in self.results)\n",
    "        num_samples = sum(result['batch_size'] for result in self.results)\n",
    "        return dict(iou=total_iou / num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.evaluator import BaseMetric\n",
    "\n",
    "class IoU(BaseMetric):\n",
    "\n",
    "    def process(self, data_batch, data_samples):\n",
    "        preds, labels = data_samples[0], data_samples[1]['labels']\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        intersect = (labels == preds).sum()\n",
    "        union = (torch.logical_or(preds, labels)).sum()\n",
    "        iou = (intersect / union).cpu()\n",
    "        self.results.append(\n",
    "            dict(batch_size=len(labels), iou=iou * len(labels)))\n",
    "\n",
    "    def compute_metrics(self, results):\n",
    "        total_iou = sum(result['iou'] for result in self.results)\n",
    "        num_samples = sum(result['batch_size'] for result in self.results)\n",
    "        return dict(iou=total_iou / num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.hooks import Hook\n",
    "import shutil\n",
    "import cv2\n",
    "import os.path as osp\n",
    "\n",
    "\n",
    "class SegVisHook(Hook):\n",
    "\n",
    "    def __init__(self, data_root, vis_num=1) -> None:\n",
    "        super().__init__()\n",
    "        self.vis_num = vis_num\n",
    "        self.palette = create_palette(osp.join(data_root, 'class_dict.csv'))\n",
    "\n",
    "    def after_val_iter(self,\n",
    "                       runner,\n",
    "                       batch_idx: int,\n",
    "                       data_batch=None,\n",
    "                       outputs=None) -> None:\n",
    "        if batch_idx > self.vis_num:\n",
    "            return\n",
    "        preds, data_samples = outputs\n",
    "        img_paths = data_samples['img_path']\n",
    "        mask_paths = data_samples['mask_path']\n",
    "        _, C, H, W = preds.shape\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        for idx, (pred, img_path,\n",
    "                  mask_path) in enumerate(zip(preds, img_paths, mask_paths)):\n",
    "            pred_mask = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "            runner.visualizer.set_image(pred_mask)\n",
    "            for color, class_id in self.palette.items():\n",
    "                runner.visualizer.draw_binary_masks(\n",
    "                    pred == class_id,\n",
    "                    colors=[color],\n",
    "                    alphas=1.0,\n",
    "                )\n",
    "            # Convert RGB to BGR\n",
    "            pred_mask = runner.visualizer.get_image()[..., ::-1]\n",
    "            saved_dir = osp.join(runner.log_dir, 'vis_data', str(idx))\n",
    "            os.makedirs(saved_dir, exist_ok=True)\n",
    "\n",
    "            shutil.copyfile(img_path,\n",
    "                            osp.join(saved_dir, osp.basename(img_path)))\n",
    "            shutil.copyfile(mask_path,\n",
    "                            osp.join(saved_dir, osp.basename(mask_path)))\n",
    "            cv2.imwrite(\n",
    "                osp.join(saved_dir, f'pred_{osp.basename(img_path)}'),\n",
    "                pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/alberto/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:15<00:00, 6.46MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/25 23:30:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1943324517\n",
      "    GPU 0: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "    CUDA_HOME: /usr/lib/cuda\n",
      "    NVCC: Not Available\n",
      "    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "    PyTorch: 1.12.0+cu113\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.0+cu113\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1943324517\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: /usr/lib/cuda/bin/nvcc: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/25 23:30:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/25 23:30:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisHook                         \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "03/25 23:30:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Dataset CamVid has no metainfo. ``dataset_meta`` in visualizer will be None.\n",
      "03/25 23:30:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoU.\n",
      "03/25 23:30:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Dataset CamVid has no metainfo. ``dataset_meta`` in evaluator, metric and visualizer will be None.\n",
      "03/25 23:30:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/25 23:30:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "03/25 23:30:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /home/alberto/Documentos/GitHub/OR_FashionParsing/work_dir.\n",
      "03/25 23:30:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10/123]  lr: 2.0000e-04  eta: 0:33:48  time: 1.6628  data_time: 0.0931  memory: 5473  loss: 2.1686\n",
      "03/25 23:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 20/123]  lr: 2.0000e-04  eta: 0:32:09  time: 1.5268  data_time: 0.0906  memory: 5473  loss: 1.1683\n",
      "03/25 23:31:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 30/123]  lr: 2.0000e-04  eta: 0:31:25  time: 1.5253  data_time: 0.0869  memory: 5473  loss: 1.0578\n",
      "03/25 23:31:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 40/123]  lr: 2.0000e-04  eta: 0:30:56  time: 1.5268  data_time: 0.0876  memory: 5473  loss: 0.8618\n",
      "03/25 23:31:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 50/123]  lr: 2.0000e-04  eta: 0:30:34  time: 1.5299  data_time: 0.0909  memory: 5473  loss: 0.7921\n",
      "03/25 23:31:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 60/123]  lr: 2.0000e-04  eta: 0:30:12  time: 1.5253  data_time: 0.0855  memory: 5473  loss: 0.7427\n",
      "03/25 23:32:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 70/123]  lr: 2.0000e-04  eta: 0:29:54  time: 1.5302  data_time: 0.0895  memory: 5473  loss: 0.6709\n",
      "03/25 23:32:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 80/123]  lr: 2.0000e-04  eta: 0:29:36  time: 1.5293  data_time: 0.0885  memory: 5473  loss: 0.6436\n",
      "03/25 23:32:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 90/123]  lr: 2.0000e-04  eta: 0:29:18  time: 1.5288  data_time: 0.0878  memory: 5473  loss: 0.6424\n",
      "03/25 23:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/123]  lr: 2.0000e-04  eta: 0:29:01  time: 1.5292  data_time: 0.0877  memory: 5473  loss: 0.6277\n",
      "03/25 23:33:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][110/123]  lr: 2.0000e-04  eta: 0:28:45  time: 1.5346  data_time: 0.0918  memory: 5473  loss: 0.5680\n",
      "03/25 23:33:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][120/123]  lr: 2.0000e-04  eta: 0:28:29  time: 1.5334  data_time: 0.0918  memory: 5473  loss: 0.5695\n",
      "03/25 23:33:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20240325_233011\n",
      "03/25 23:33:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/25 23:33:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "03/25 23:33:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 10/123]  lr: 2.0000e-04  eta: 0:28:07  time: 1.5196  data_time: 0.0775  memory: 5473  loss: 0.5351\n",
      "03/25 23:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 20/123]  lr: 2.0000e-04  eta: 0:27:50  time: 1.5177  data_time: 0.0764  memory: 5473  loss: 0.4763\n",
      "03/25 23:34:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 30/123]  lr: 2.0000e-04  eta: 0:27:34  time: 1.5202  data_time: 0.0787  memory: 5473  loss: 0.5214\n",
      "03/25 23:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 40/123]  lr: 2.0000e-04  eta: 0:27:17  time: 1.5200  data_time: 0.0782  memory: 5473  loss: 0.4645\n",
      "03/25 23:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 50/123]  lr: 2.0000e-04  eta: 0:27:01  time: 1.5210  data_time: 0.0786  memory: 5473  loss: 0.4299\n",
      "03/25 23:34:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 60/123]  lr: 2.0000e-04  eta: 0:26:45  time: 1.5192  data_time: 0.0776  memory: 5473  loss: 0.4467\n",
      "03/25 23:35:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 70/123]  lr: 2.0000e-04  eta: 0:26:29  time: 1.5190  data_time: 0.0775  memory: 5473  loss: 0.5013\n",
      "03/25 23:35:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 80/123]  lr: 2.0000e-04  eta: 0:26:13  time: 1.5194  data_time: 0.0772  memory: 5473  loss: 0.4257\n",
      "03/25 23:35:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 90/123]  lr: 2.0000e-04  eta: 0:25:57  time: 1.5182  data_time: 0.0762  memory: 5473  loss: 0.4438\n",
      "03/25 23:35:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/123]  lr: 2.0000e-04  eta: 0:25:41  time: 1.5226  data_time: 0.0795  memory: 5473  loss: 0.3646\n",
      "03/25 23:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][110/123]  lr: 2.0000e-04  eta: 0:25:26  time: 1.5241  data_time: 0.0811  memory: 5473  loss: 0.3743\n",
      "03/25 23:36:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][120/123]  lr: 2.0000e-04  eta: 0:25:10  time: 1.5209  data_time: 0.0783  memory: 5473  loss: 0.4794\n",
      "03/25 23:36:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20240325_233011\n",
      "03/25 23:36:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "03/25 23:36:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 10/123]  lr: 2.0000e-04  eta: 0:24:50  time: 1.5250  data_time: 0.0815  memory: 5473  loss: 0.3571\n",
      "03/25 23:37:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 20/123]  lr: 2.0000e-04  eta: 0:24:34  time: 1.5215  data_time: 0.0799  memory: 5473  loss: 0.3300\n",
      "03/25 23:37:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 30/123]  lr: 2.0000e-04  eta: 0:24:19  time: 1.5238  data_time: 0.0812  memory: 5473  loss: 0.3207\n",
      "03/25 23:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 40/123]  lr: 2.0000e-04  eta: 0:24:03  time: 1.5277  data_time: 0.0848  memory: 5473  loss: 0.3441\n",
      "03/25 23:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 50/123]  lr: 2.0000e-04  eta: 0:23:48  time: 1.5205  data_time: 0.0784  memory: 5473  loss: 0.3436\n",
      "03/25 23:38:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 60/123]  lr: 2.0000e-04  eta: 0:23:32  time: 1.5213  data_time: 0.0794  memory: 5473  loss: 0.3400\n",
      "03/25 23:38:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 70/123]  lr: 2.0000e-04  eta: 0:23:17  time: 1.5241  data_time: 0.0819  memory: 5473  loss: 0.3212\n",
      "03/25 23:38:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 80/123]  lr: 2.0000e-04  eta: 0:23:01  time: 1.5214  data_time: 0.0795  memory: 5473  loss: 0.2951\n",
      "03/25 23:38:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 90/123]  lr: 2.0000e-04  eta: 0:22:46  time: 1.5226  data_time: 0.0801  memory: 5473  loss: 0.3686\n",
      "03/25 23:39:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/123]  lr: 2.0000e-04  eta: 0:22:30  time: 1.5199  data_time: 0.0780  memory: 5473  loss: 0.3131\n",
      "03/25 23:39:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][110/123]  lr: 2.0000e-04  eta: 0:22:15  time: 1.5221  data_time: 0.0795  memory: 5473  loss: 0.2964\n",
      "03/25 23:39:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][120/123]  lr: 2.0000e-04  eta: 0:21:59  time: 1.5212  data_time: 0.0786  memory: 5473  loss: 0.2704\n",
      "03/25 23:39:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20240325_233011\n",
      "03/25 23:39:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "03/25 23:39:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 10/123]  lr: 2.0000e-04  eta: 0:21:39  time: 1.5232  data_time: 0.0802  memory: 5473  loss: 0.2710\n",
      "03/25 23:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 20/123]  lr: 2.0000e-04  eta: 0:21:24  time: 1.5229  data_time: 0.0803  memory: 5473  loss: 0.2935\n",
      "03/25 23:40:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 30/123]  lr: 2.0000e-04  eta: 0:21:09  time: 1.5217  data_time: 0.0791  memory: 5473  loss: 0.2683\n",
      "03/25 23:40:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 40/123]  lr: 2.0000e-04  eta: 0:20:53  time: 1.5202  data_time: 0.0784  memory: 5473  loss: 0.3136\n",
      "03/25 23:40:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 50/123]  lr: 2.0000e-04  eta: 0:20:38  time: 1.5245  data_time: 0.0810  memory: 5473  loss: 0.3021\n",
      "03/25 23:41:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 60/123]  lr: 2.0000e-04  eta: 0:20:23  time: 1.5229  data_time: 0.0800  memory: 5473  loss: 0.2665\n",
      "03/25 23:41:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 70/123]  lr: 2.0000e-04  eta: 0:20:07  time: 1.5245  data_time: 0.0816  memory: 5473  loss: 0.2664\n",
      "03/25 23:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 80/123]  lr: 2.0000e-04  eta: 0:19:52  time: 1.5224  data_time: 0.0802  memory: 5473  loss: 0.2739\n",
      "03/25 23:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 90/123]  lr: 2.0000e-04  eta: 0:19:37  time: 1.5229  data_time: 0.0805  memory: 5473  loss: 0.2463\n",
      "03/25 23:42:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/123]  lr: 2.0000e-04  eta: 0:19:21  time: 1.5256  data_time: 0.0826  memory: 5473  loss: 0.2786\n",
      "03/25 23:42:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][110/123]  lr: 2.0000e-04  eta: 0:19:06  time: 1.5274  data_time: 0.0841  memory: 5473  loss: 0.2641\n",
      "03/25 23:42:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][120/123]  lr: 2.0000e-04  eta: 0:18:51  time: 1.5269  data_time: 0.0839  memory: 5473  loss: 0.2285\n",
      "03/25 23:42:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20240325_233011\n",
      "03/25 23:42:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "03/25 23:43:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 10/123]  lr: 2.0000e-04  eta: 0:18:31  time: 1.5259  data_time: 0.0831  memory: 5473  loss: 0.2092\n",
      "03/25 23:43:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 20/123]  lr: 2.0000e-04  eta: 0:18:16  time: 1.5276  data_time: 0.0843  memory: 5473  loss: 0.2318\n",
      "03/25 23:43:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 30/123]  lr: 2.0000e-04  eta: 0:18:00  time: 1.5264  data_time: 0.0827  memory: 5473  loss: 0.2179\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m      6\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m  \u001b[38;5;66;03m# Modify to actual number of categories.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m runner \u001b[38;5;241m=\u001b[39m Runner(\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m=\u001b[39mMMDeeplabV3(num_classes),\n\u001b[1;32m     10\u001b[0m     work_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./work_dir\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     default_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheckpointHook\u001b[39m\u001b[38;5;124m'\u001b[39m, interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab2/lib/python3.10/site-packages/mmengine/runner/runner.py:1777\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;66;03m# Maybe compile the model according to options in self.cfg.compile\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;66;03m# This must be called **AFTER** model has been wrapped.\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_compile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_step\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1777\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab2/lib/python3.10/site-packages/mmengine/runner/loops.py:96\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decide_current_val_interval()\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mval_loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_begin\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab2/lib/python3.10/site-packages/mmengine/runner/loops.py:112\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab2/lib/python3.10/site-packages/mmengine/runner/loops.py:128\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_iter\u001b[0;34m(self, idx, data_batch)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_idx\u001b[38;5;241m=\u001b[39midx, data_batch\u001b[38;5;241m=\u001b[39mdata_batch)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Enable gradient accumulation mode and avoid unnecessary gradient\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# synchronization during gradient accumulation process.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# outputs should be a dict of loss.\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    133\u001b[0m     batch_idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[1;32m    134\u001b[0m     data_batch\u001b[38;5;241m=\u001b[39mdata_batch,\n\u001b[1;32m    135\u001b[0m     outputs\u001b[38;5;241m=\u001b[39moutputs)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab2/lib/python3.10/site-packages/mmengine/model/base_model/base_model.py:116\u001b[0m, in \u001b[0;36mBaseModel.train_step\u001b[0;34m(self, data, optim_wrapper)\u001b[0m\n\u001b[1;32m    114\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_forward(data, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    115\u001b[0m parsed_losses, log_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_losses(losses)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[43moptim_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_losses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_vars\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab2/lib/python3.10/site-packages/mmengine/optim/optimizer/optimizer_wrapper.py:201\u001b[0m, in \u001b[0;36mOptimWrapper.update_params\u001b[0;34m(self, loss, step_kwargs, zero_kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Update parameters only if `self._inner_count` is divisible by\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# `self._accumulative_counts` or `self._inner_count` equals to\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# `self._max_counts`\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_update():\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_grad(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mzero_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab2/lib/python3.10/site-packages/mmengine/optim/optimizer/amp_optimizer_wrapper.py:139\u001b[0m, in \u001b[0;36mAmpOptimWrapper.step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_scaler\u001b[38;5;241m.\u001b[39munscale_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clip_grad()\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_scaler\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale_update_param)\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab2/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:338\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 338\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab2/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:284\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    283\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    285\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab2/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:284\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    283\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    285\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from mmengine.optim import AmpOptimWrapper\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "\n",
    "num_classes = 32  # Modify to actual number of categories.\n",
    "\n",
    "runner = Runner(\n",
    "    model=MMDeeplabV3(num_classes),\n",
    "    work_dir='./work_dir',\n",
    "    train_dataloader=train_dataloader,\n",
    "    optim_wrapper=dict(\n",
    "        type=AmpOptimWrapper, optimizer=dict(type=AdamW, lr=2e-4)),\n",
    "    train_cfg=dict(by_epoch=True, max_epochs=10, val_interval=10),\n",
    "    val_dataloader=val_dataloader,\n",
    "    val_cfg=dict(),\n",
    "    val_evaluator=dict(type=IoU),\n",
    "    custom_hooks=[SegVisHook('data/CamVid')],\n",
    "    default_hooks=dict(checkpoint=dict(type='CheckpointHook', interval=1)),\n",
    ")\n",
    "runner.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
