2024/04/20 18:49:01 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: win32
    Python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 0
    GPU 0: NVIDIA GeForce RTX 3060 Ti
    CUDA_HOME: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.2
    NVCC: Cuda compilation tools, release 12.2, V12.2.140
    MSVC: Compilador de optimización de C/C++ de Microsoft (R) versión 19.34.31948 para x64
    GCC: n/a
    PyTorch: 1.12.0+cu113
    PyTorch compiling details: PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/actions-runner/_work/pytorch/pytorch/builder/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.13.0+cu113
    OpenCV: 4.9.0
    MMEngine: 0.10.3

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 0
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2024/04/20 18:49:01 - mmengine - INFO - Config:
cfg = dict(
    crop_size=(
        384,
        384,
    ),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    data_root='../datasets/fashion/',
    dataset_type='FashionBG',
    default_hooks=dict(
        checkpoint=dict(by_epoch=False, interval=4000, type='CheckpointHook'),
        logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
        param_scheduler=dict(type='ParamSchedulerHook'),
        sampler_seed=dict(type='DistSamplerSeedHook'),
        timer=dict(type='IterTimerHook'),
        visualization=dict(type='SegVisualizationHook')),
    default_scope='mmseg',
    env_cfg=dict(
        cudnn_benchmark=True,
        dist_cfg=dict(backend='nccl'),
        mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0)),
    img_ratios=[
        0.5,
        0.75,
        1.0,
        1.25,
        1.5,
        1.75,
    ],
    load_from=
    './checkpoints/upernet_deit-s16_mln_512x512_160k_ade20k_20210621_161021-fb9a5dfb.pth',
    log_level='INFO',
    log_processor=dict(by_epoch=False),
    model=dict(
        auxiliary_head=dict(
            align_corners=False,
            channels=256,
            concat_input=False,
            dropout_ratio=0.1,
            in_channels=384,
            in_index=3,
            loss_decode=dict(
                loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
            norm_cfg=dict(requires_grad=True, type='SyncBN'),
            num_classes=47,
            num_convs=1,
            type='FCNHead'),
        backbone=dict(
            act_cfg=dict(type='GELU'),
            attn_drop_rate=0.0,
            drop_path_rate=0.1,
            drop_rate=0.0,
            embed_dims=384,
            img_size=(
                512,
                512,
            ),
            in_channels=3,
            interpolate_mode='bicubic',
            mlp_ratio=4,
            norm_cfg=dict(eps=1e-06, type='LN'),
            norm_eval=False,
            num_heads=6,
            num_layers=12,
            out_indices=(
                2,
                5,
                8,
                11,
            ),
            patch_size=16,
            qkv_bias=True,
            type='VisionTransformer',
            with_cls_token=True),
        data_preprocessor=dict(
            bgr_to_rgb=True,
            mean=[
                135.43535295,
                125.5206132,
                122.8418554,
            ],
            pad_val=0,
            seg_pad_val=255,
            size=(
                384,
                384,
            ),
            std=[
                64.70508792,
                63.73913779,
                62.8355091,
            ],
            type='SegDataPreProcessor'),
        decode_head=dict(
            align_corners=False,
            channels=512,
            dropout_ratio=0.1,
            in_channels=[
                384,
                384,
                384,
                384,
            ],
            in_index=[
                0,
                1,
                2,
                3,
            ],
            loss_decode=dict(
                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
            norm_cfg=dict(requires_grad=True, type='SyncBN'),
            num_classes=47,
            pool_scales=(
                1,
                2,
                3,
                6,
            ),
            type='UPerHead'),
        neck=None,
        pretrained='pretrain/deit_small_patch16_224-cd65a155.pth',
        test_cfg=dict(mode='whole'),
        train_cfg=dict(),
        type='EncoderDecoder'),
    norm_cfg=dict(requires_grad=True, type='SyncBN'),
    optim_wrapper=dict(
        clip_grad=None,
        optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
        type='OptimWrapper'),
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    param_scheduler=[
        dict(
            begin=0,
            by_epoch=False,
            end=40000,
            eta_min=0.0001,
            power=0.9,
            type='PolyLR'),
    ],
    randomness=dict(seed=0),
    resume=False,
    test_cfg=dict(type='TestLoop'),
    test_dataloader=dict(
        batch_size=1,
        dataset=dict(
            ann_file=0,
            data_prefix=dict(
                img_path='images/val2020', seg_map_path='annotations/val2020'),
            data_root='../datasets/fashion/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(keep_ratio=True, scale=(
                    320,
                    240,
                ), type='Resize'),
                dict(type='LoadAnnotations'),
                dict(type='PackSegInputs'),
            ],
            type='FashionBG'),
        num_workers=4,
        persistent_workers=True,
        sampler=dict(shuffle=False, type='DefaultSampler')),
    test_evaluator=dict(
        classwise=True,
        ignore_index=0,
        iou_metrics=[
            'mIoU',
            'mDice',
        ],
        type='IoUMetric'),
    test_pipeline=[
        dict(type='LoadImageFromFile'),
        dict(keep_ratio=True, scale=(
            320,
            240,
        ), type='Resize'),
        dict(type='LoadAnnotations'),
        dict(type='PackSegInputs'),
    ],
    train_cfg=dict(
        max_iters=40000, type='IterBasedTrainLoop', val_interval=4000),
    train_dataloader=dict(
        batch_size=16,
        dataset=dict(
            ann_file=0,
            data_prefix=dict(
                img_path='images/train2020',
                seg_map_path='annotations/train2020'),
            data_root='../datasets/fashion/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations'),
                dict(
                    transforms=[
                        dict(limit=20, p=0.5, type='Rotate'),
                        dict(
                            p=0.5,
                            rotate_limit=20,
                            scale_limit=0.1,
                            shift_limit=0.1,
                            type='ShiftScaleRotate'),
                    ],
                    type='Albu'),
                dict(
                    keep_ratio=True,
                    ratio_range=(
                        0.5,
                        2.0,
                    ),
                    scale=(
                        320,
                        240,
                    ),
                    type='RandomResize'),
                dict(
                    cat_max_ratio=0.75,
                    crop_size=(
                        384,
                        384,
                    ),
                    type='RandomCrop'),
                dict(prob=0.5, type='RandomFlip'),
                dict(type='PackSegInputs'),
            ],
            type='FashionBG'),
        num_workers=4,
        persistent_workers=True,
        sampler=dict(shuffle=True, type='InfiniteSampler')),
    train_pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            transforms=[
                dict(limit=20, p=0.5, type='Rotate'),
                dict(
                    p=0.5,
                    rotate_limit=20,
                    scale_limit=0.1,
                    shift_limit=0.1,
                    type='ShiftScaleRotate'),
            ],
            type='Albu'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                320,
                240,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            384,
            384,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PackSegInputs'),
    ],
    tta_model=dict(type='SegTTAModel'),
    tta_pipeline=[
        dict(backend_args=None, type='LoadImageFromFile'),
        dict(
            transforms=[
                [
                    dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                    dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                    dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                    dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                    dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                    dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
                ],
                [
                    dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                    dict(direction='horizontal', prob=1.0, type='RandomFlip'),
                ],
                [
                    dict(type='LoadAnnotations'),
                ],
                [
                    dict(type='PackSegInputs'),
                ],
            ],
            type='TestTimeAug'),
    ],
    val_cfg=dict(type='ValLoop'),
    val_dataloader=dict(
        batch_size=1,
        dataset=dict(
            ann_file=0,
            data_prefix=dict(
                img_path='images/val2020', seg_map_path='annotations/val2020'),
            data_root='../datasets/fashion/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(keep_ratio=True, scale=(
                    320,
                    240,
                ), type='Resize'),
                dict(type='LoadAnnotations'),
                dict(type='PackSegInputs'),
            ],
            type='FashionBG'),
        num_workers=4,
        persistent_workers=True,
        sampler=dict(shuffle=False, type='DefaultSampler')),
    val_evaluator=dict(
        classwise=True,
        ignore_index=0,
        iou_metrics=[
            'mIoU',
            'mDice',
        ],
        type='IoUMetric'),
    vis_backends=[
        dict(type='LocalVisBackend'),
    ],
    visualizer=dict(
        name='visualizer',
        type='SegLocalVisualizer',
        vis_backends=[
            dict(type='LocalVisBackend'),
        ]),
    work_dir='./work_dirs/tutorial')
crop_size = (
    384,
    384,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        135.43535295,
        125.5206132,
        122.8418554,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        64.70508792,
        63.73913779,
        62.8355091,
    ],
    type='SegDataPreProcessor')
data_root = '../datasets/fashion/'
dataset_type = 'FashionBG'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=4000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = './checkpoints/upernet_deit-s16_mln_512x512_160k_ade20k_20210621_161021-fb9a5dfb.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=384,
        in_index=3,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=47,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        act_cfg=dict(type='GELU'),
        attn_drop_rate=0.0,
        drop_path_rate=0.1,
        drop_rate=0.0,
        embed_dims=384,
        img_size=(
            512,
            512,
        ),
        in_channels=3,
        interpolate_mode='bicubic',
        mlp_ratio=4,
        norm_cfg=dict(eps=1e-06, type='LN'),
        norm_eval=False,
        num_heads=6,
        num_layers=12,
        out_indices=(
            2,
            5,
            8,
            11,
        ),
        patch_size=16,
        qkv_bias=True,
        type='VisionTransformer',
        with_cls_token=True),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            135.43535295,
            125.5206132,
            122.8418554,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            384,
            384,
        ),
        std=[
            64.70508792,
            63.73913779,
            62.8355091,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            384,
            384,
            384,
            384,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=47,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    neck=None,
    pretrained='pretrain/deit_small_patch16_224-cd65a155.pth',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
name = 'vit'
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=40000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=0)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file=0,
        data_prefix=dict(
            img_path='images/val2020', seg_map_path='annotations/val2020'),
        data_root='../datasets/fashion/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                320,
                240,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='FashionBG'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True,
    ignore_index=0,
    iou_metrics=[
        'mIoU',
        'mDice',
    ],
    type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        320,
        240,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(max_iters=40000, type='IterBasedTrainLoop', val_interval=4000)
train_dataloader = dict(
    batch_size=16,
    dataset=dict(
        ann_file=0,
        data_prefix=dict(
            img_path='images/train2020', seg_map_path='annotations/train2020'),
        data_root='../datasets/fashion/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                transforms=[
                    dict(limit=20, p=0.5, type='Rotate'),
                    dict(
                        p=0.5,
                        rotate_limit=20,
                        scale_limit=0.1,
                        shift_limit=0.1,
                        type='ShiftScaleRotate'),
                ],
                type='Albu'),
            dict(
                keep_ratio=True,
                ratio_range=(
                    0.5,
                    2.0,
                ),
                scale=(
                    320,
                    240,
                ),
                type='RandomResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    384,
                    384,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PackSegInputs'),
        ],
        type='FashionBG'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        transforms=[
            dict(limit=20, p=0.5, type='Rotate'),
            dict(
                p=0.5,
                rotate_limit=20,
                scale_limit=0.1,
                shift_limit=0.1,
                type='ShiftScaleRotate'),
        ],
        type='Albu'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            320,
            240,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        384,
        384,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file=0,
        data_prefix=dict(
            img_path='images/val2020', seg_map_path='annotations/val2020'),
        data_root='../datasets/fashion/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                320,
                240,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='FashionBG'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    classwise=True,
    ignore_index=0,
    iou_metrics=[
        'mIoU',
        'mDice',
    ],
    type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/vit/schedule_40000/resol_384'

2024/04/20 18:49:03 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2024/04/20 18:49:03 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/04/20 18:49:12 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Name of parameter - Initialization information

backbone.cls_token - torch.Size([1, 1, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.pos_embed - torch.Size([1, 1025, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.projection.weight - torch.Size([384, 3, 16, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.0.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.1.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.2.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.3.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.4.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.5.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.6.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.7.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.8.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.9.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.10.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.ln1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.ln1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.attn.attn.in_proj_weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.attn.attn.in_proj_bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.attn.attn.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.attn.attn.out_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.ln2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.ln2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.ffn.layers.0.0.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.ffn.layers.1.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.layers.11.ffn.layers.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([47, 512, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([47]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.psp_modules.0.1.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.conv.weight - torch.Size([512, 2432, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.bottleneck.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_bottleneck.conv.weight - torch.Size([512, 2048, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.fpn_bottleneck.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_bottleneck.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.conv_seg.weight - torch.Size([47, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.conv_seg.bias - torch.Size([47]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.convs.0.conv.weight - torch.Size([256, 384, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2024/04/20 18:49:15 - mmengine - INFO - Load checkpoint from ./checkpoints/upernet_deit-s16_mln_512x512_160k_ade20k_20210621_161021-fb9a5dfb.pth
2024/04/20 18:49:15 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/04/20 18:49:15 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/04/20 18:49:15 - mmengine - INFO - Checkpoints will be saved to C:\Users\xavie\OneDrive\Documentos\MAI\OR\OR_FashionParsing\mmsegmentation\work_dirs\vit\schedule_40000\resol_384.
2024/04/20 18:49:58 - mmengine - INFO - Iter(train) [   50/40000]  lr: 9.9891e-03  eta: 9:41:21  time: 0.7816  data_time: 0.0035  memory: 7388  loss: 0.8209  decode.loss_ce: 0.5809  decode.acc_seg: 71.5064  aux.loss_ce: 0.2400  aux.acc_seg: 71.2834
2024/04/20 18:50:38 - mmengine - INFO - Iter(train) [  100/40000]  lr: 9.9779e-03  eta: 9:10:40  time: 0.7802  data_time: 0.0035  memory: 7388  loss: 0.5983  decode.loss_ce: 0.4255  decode.acc_seg: 85.2172  aux.loss_ce: 0.1728  aux.acc_seg: 83.9759
2024/04/20 18:51:17 - mmengine - INFO - Iter(train) [  150/40000]  lr: 9.9668e-03  eta: 9:00:00  time: 0.7804  data_time: 0.0035  memory: 7388  loss: 0.5936  decode.loss_ce: 0.4164  decode.acc_seg: 82.8155  aux.loss_ce: 0.1772  aux.acc_seg: 82.4397
2024/04/20 18:51:56 - mmengine - INFO - Iter(train) [  200/40000]  lr: 9.9557e-03  eta: 8:54:03  time: 0.7844  data_time: 0.0037  memory: 7388  loss: 0.6640  decode.loss_ce: 0.4659  decode.acc_seg: 81.9517  aux.loss_ce: 0.1981  aux.acc_seg: 86.2754
2024/04/20 18:52:35 - mmengine - INFO - Iter(train) [  250/40000]  lr: 9.9445e-03  eta: 8:50:17  time: 0.7807  data_time: 0.0035  memory: 7388  loss: 0.4943  decode.loss_ce: 0.3481  decode.acc_seg: 83.7971  aux.loss_ce: 0.1462  aux.acc_seg: 82.5659
2024/04/20 18:53:14 - mmengine - INFO - Iter(train) [  300/40000]  lr: 9.9334e-03  eta: 8:47:29  time: 0.7786  data_time: 0.0035  memory: 7388  loss: 0.5027  decode.loss_ce: 0.3547  decode.acc_seg: 82.7640  aux.loss_ce: 0.1480  aux.acc_seg: 80.3905
2024/04/20 18:53:53 - mmengine - INFO - Iter(train) [  350/40000]  lr: 9.9222e-03  eta: 8:45:16  time: 0.7812  data_time: 0.0033  memory: 7388  loss: 0.4369  decode.loss_ce: 0.3085  decode.acc_seg: 90.8842  aux.loss_ce: 0.1284  aux.acc_seg: 91.1988
2024/04/20 18:54:32 - mmengine - INFO - Iter(train) [  400/40000]  lr: 9.9111e-03  eta: 8:43:27  time: 0.7813  data_time: 0.0034  memory: 7388  loss: 0.5020  decode.loss_ce: 0.3581  decode.acc_seg: 88.1418  aux.loss_ce: 0.1439  aux.acc_seg: 88.7995
2024/04/20 18:55:11 - mmengine - INFO - Iter(train) [  450/40000]  lr: 9.8999e-03  eta: 8:41:53  time: 0.7801  data_time: 0.0033  memory: 7388  loss: 0.4633  decode.loss_ce: 0.3299  decode.acc_seg: 86.1404  aux.loss_ce: 0.1334  aux.acc_seg: 85.8104
2024/04/20 18:55:50 - mmengine - INFO - Iter(train) [  500/40000]  lr: 9.8888e-03  eta: 8:40:25  time: 0.7790  data_time: 0.0036  memory: 7388  loss: 0.4680  decode.loss_ce: 0.3351  decode.acc_seg: 83.8221  aux.loss_ce: 0.1328  aux.acc_seg: 88.3109
2024/04/20 18:56:29 - mmengine - INFO - Iter(train) [  550/40000]  lr: 9.8776e-03  eta: 8:39:03  time: 0.7767  data_time: 0.0033  memory: 7388  loss: 0.4648  decode.loss_ce: 0.3331  decode.acc_seg: 85.8549  aux.loss_ce: 0.1316  aux.acc_seg: 86.7683
2024/04/20 18:57:08 - mmengine - INFO - Iter(train) [  600/40000]  lr: 9.8665e-03  eta: 8:37:50  time: 0.7785  data_time: 0.0033  memory: 7388  loss: 0.4353  decode.loss_ce: 0.3079  decode.acc_seg: 84.0983  aux.loss_ce: 0.1274  aux.acc_seg: 84.8534
2024/04/20 18:57:47 - mmengine - INFO - Iter(train) [  650/40000]  lr: 9.8553e-03  eta: 8:36:58  time: 0.7839  data_time: 0.0047  memory: 7388  loss: 0.3949  decode.loss_ce: 0.2818  decode.acc_seg: 91.2438  aux.loss_ce: 0.1130  aux.acc_seg: 91.9740
2024/04/20 18:58:26 - mmengine - INFO - Iter(train) [  700/40000]  lr: 9.8442e-03  eta: 8:35:56  time: 0.7789  data_time: 0.0034  memory: 7388  loss: 0.4797  decode.loss_ce: 0.3407  decode.acc_seg: 89.0691  aux.loss_ce: 0.1390  aux.acc_seg: 88.5227
2024/04/20 18:59:05 - mmengine - INFO - Iter(train) [  750/40000]  lr: 9.8330e-03  eta: 8:34:58  time: 0.7803  data_time: 0.0034  memory: 7388  loss: 0.4047  decode.loss_ce: 0.2877  decode.acc_seg: 82.2282  aux.loss_ce: 0.1170  aux.acc_seg: 81.9082
2024/04/20 18:59:44 - mmengine - INFO - Iter(train) [  800/40000]  lr: 9.8218e-03  eta: 8:34:01  time: 0.7799  data_time: 0.0035  memory: 7388  loss: 0.4534  decode.loss_ce: 0.3235  decode.acc_seg: 84.4042  aux.loss_ce: 0.1298  aux.acc_seg: 86.3067
2024/04/20 19:00:23 - mmengine - INFO - Iter(train) [  850/40000]  lr: 9.8107e-03  eta: 8:33:08  time: 0.7813  data_time: 0.0033  memory: 7388  loss: 0.3815  decode.loss_ce: 0.2687  decode.acc_seg: 88.2295  aux.loss_ce: 0.1128  aux.acc_seg: 88.2645
2024/04/20 19:01:02 - mmengine - INFO - Iter(train) [  900/40000]  lr: 9.7995e-03  eta: 8:32:14  time: 0.7785  data_time: 0.0034  memory: 7388  loss: 0.4475  decode.loss_ce: 0.3192  decode.acc_seg: 80.8800  aux.loss_ce: 0.1283  aux.acc_seg: 81.1330
2024/04/20 19:01:41 - mmengine - INFO - Iter(train) [  950/40000]  lr: 9.7884e-03  eta: 8:31:20  time: 0.7783  data_time: 0.0034  memory: 7388  loss: 0.4130  decode.loss_ce: 0.2929  decode.acc_seg: 87.5445  aux.loss_ce: 0.1201  aux.acc_seg: 86.8169
2024/04/20 19:02:20 - mmengine - INFO - Exp name: vit_deit-s16_mln_upernet_8xb2-40k-384x384_20240420_184859
2024/04/20 19:02:20 - mmengine - INFO - Iter(train) [ 1000/40000]  lr: 9.7772e-03  eta: 8:30:30  time: 0.7837  data_time: 0.0035  memory: 7388  loss: 0.4139  decode.loss_ce: 0.2943  decode.acc_seg: 91.4687  aux.loss_ce: 0.1196  aux.acc_seg: 91.3893
2024/04/20 19:02:59 - mmengine - INFO - Iter(train) [ 1050/40000]  lr: 9.7660e-03  eta: 8:29:40  time: 0.7777  data_time: 0.0034  memory: 7388  loss: 0.4164  decode.loss_ce: 0.2964  decode.acc_seg: 86.9749  aux.loss_ce: 0.1200  aux.acc_seg: 87.1316
2024/04/20 19:03:38 - mmengine - INFO - Iter(train) [ 1100/40000]  lr: 9.7549e-03  eta: 8:28:52  time: 0.7806  data_time: 0.0035  memory: 7388  loss: 0.4277  decode.loss_ce: 0.3009  decode.acc_seg: 85.8870  aux.loss_ce: 0.1268  aux.acc_seg: 85.4508
2024/04/20 19:04:17 - mmengine - INFO - Iter(train) [ 1150/40000]  lr: 9.7437e-03  eta: 8:28:03  time: 0.7787  data_time: 0.0035  memory: 7388  loss: 0.3775  decode.loss_ce: 0.2701  decode.acc_seg: 88.4184  aux.loss_ce: 0.1074  aux.acc_seg: 88.8859
2024/04/20 19:04:56 - mmengine - INFO - Iter(train) [ 1200/40000]  lr: 9.7325e-03  eta: 8:27:15  time: 0.7768  data_time: 0.0033  memory: 7388  loss: 0.4397  decode.loss_ce: 0.3115  decode.acc_seg: 79.3648  aux.loss_ce: 0.1282  aux.acc_seg: 79.4627
2024/04/20 19:05:35 - mmengine - INFO - Iter(train) [ 1250/40000]  lr: 9.7213e-03  eta: 8:26:28  time: 0.7765  data_time: 0.0034  memory: 7388  loss: 0.3806  decode.loss_ce: 0.2699  decode.acc_seg: 86.9740  aux.loss_ce: 0.1107  aux.acc_seg: 86.9042
2024/04/20 19:06:14 - mmengine - INFO - Iter(train) [ 1300/40000]  lr: 9.7102e-03  eta: 8:25:38  time: 0.7766  data_time: 0.0037  memory: 7388  loss: 0.3591  decode.loss_ce: 0.2541  decode.acc_seg: 88.2662  aux.loss_ce: 0.1050  aux.acc_seg: 89.5905
2024/04/20 19:06:53 - mmengine - INFO - Iter(train) [ 1350/40000]  lr: 9.6990e-03  eta: 8:24:52  time: 0.7775  data_time: 0.0034  memory: 7388  loss: 0.4351  decode.loss_ce: 0.3081  decode.acc_seg: 87.2900  aux.loss_ce: 0.1271  aux.acc_seg: 87.2529
2024/04/20 19:07:32 - mmengine - INFO - Iter(train) [ 1400/40000]  lr: 9.6878e-03  eta: 8:24:06  time: 0.7805  data_time: 0.0038  memory: 7388  loss: 0.4619  decode.loss_ce: 0.3257  decode.acc_seg: 87.4430  aux.loss_ce: 0.1361  aux.acc_seg: 87.6281
2024/04/20 19:08:11 - mmengine - INFO - Iter(train) [ 1450/40000]  lr: 9.6766e-03  eta: 8:23:20  time: 0.7783  data_time: 0.0035  memory: 7388  loss: 0.3576  decode.loss_ce: 0.2543  decode.acc_seg: 86.2866  aux.loss_ce: 0.1033  aux.acc_seg: 86.7897
2024/04/20 19:08:50 - mmengine - INFO - Iter(train) [ 1500/40000]  lr: 9.6655e-03  eta: 8:22:35  time: 0.7789  data_time: 0.0036  memory: 7388  loss: 0.4306  decode.loss_ce: 0.3062  decode.acc_seg: 85.8801  aux.loss_ce: 0.1244  aux.acc_seg: 84.7573
2024/04/20 19:09:29 - mmengine - INFO - Iter(train) [ 1550/40000]  lr: 9.6543e-03  eta: 8:21:52  time: 0.7806  data_time: 0.0035  memory: 7388  loss: 0.4016  decode.loss_ce: 0.2852  decode.acc_seg: 90.9801  aux.loss_ce: 0.1164  aux.acc_seg: 89.9777
2024/04/20 19:10:08 - mmengine - INFO - Iter(train) [ 1600/40000]  lr: 9.6431e-03  eta: 8:21:14  time: 0.7871  data_time: 0.0048  memory: 7388  loss: 0.3854  decode.loss_ce: 0.2735  decode.acc_seg: 87.3528  aux.loss_ce: 0.1119  aux.acc_seg: 87.3235
2024/04/20 19:10:47 - mmengine - INFO - Iter(train) [ 1650/40000]  lr: 9.6319e-03  eta: 8:20:38  time: 0.7891  data_time: 0.0059  memory: 7388  loss: 0.4022  decode.loss_ce: 0.2869  decode.acc_seg: 83.5745  aux.loss_ce: 0.1153  aux.acc_seg: 83.1051
2024/04/20 19:11:26 - mmengine - INFO - Iter(train) [ 1700/40000]  lr: 9.6207e-03  eta: 8:19:59  time: 0.7816  data_time: 0.0033  memory: 7388  loss: 0.4088  decode.loss_ce: 0.2892  decode.acc_seg: 85.9752  aux.loss_ce: 0.1196  aux.acc_seg: 86.9002
2024/04/20 19:12:05 - mmengine - INFO - Iter(train) [ 1750/40000]  lr: 9.6095e-03  eta: 8:19:18  time: 0.7803  data_time: 0.0034  memory: 7388  loss: 0.3584  decode.loss_ce: 0.2539  decode.acc_seg: 87.4369  aux.loss_ce: 0.1045  aux.acc_seg: 87.3977
2024/04/20 19:12:44 - mmengine - INFO - Iter(train) [ 1800/40000]  lr: 9.5983e-03  eta: 8:18:35  time: 0.7795  data_time: 0.0038  memory: 7388  loss: 0.3380  decode.loss_ce: 0.2399  decode.acc_seg: 88.1354  aux.loss_ce: 0.0981  aux.acc_seg: 89.6665
2024/04/20 19:13:23 - mmengine - INFO - Iter(train) [ 1850/40000]  lr: 9.5872e-03  eta: 8:17:54  time: 0.7803  data_time: 0.0039  memory: 7388  loss: 0.3129  decode.loss_ce: 0.2212  decode.acc_seg: 85.7486  aux.loss_ce: 0.0917  aux.acc_seg: 84.7750
2024/04/20 19:14:02 - mmengine - INFO - Iter(train) [ 1900/40000]  lr: 9.5760e-03  eta: 8:17:12  time: 0.7796  data_time: 0.0035  memory: 7388  loss: 0.4290  decode.loss_ce: 0.3053  decode.acc_seg: 89.7940  aux.loss_ce: 0.1237  aux.acc_seg: 90.3640
2024/04/20 19:14:41 - mmengine - INFO - Iter(train) [ 1950/40000]  lr: 9.5648e-03  eta: 8:16:30  time: 0.7784  data_time: 0.0034  memory: 7388  loss: 0.3816  decode.loss_ce: 0.2724  decode.acc_seg: 85.5448  aux.loss_ce: 0.1092  aux.acc_seg: 87.1818
2024/04/20 19:15:20 - mmengine - INFO - Exp name: vit_deit-s16_mln_upernet_8xb2-40k-384x384_20240420_184859
2024/04/20 19:15:20 - mmengine - INFO - Iter(train) [ 2000/40000]  lr: 9.5536e-03  eta: 8:15:47  time: 0.7792  data_time: 0.0034  memory: 7388  loss: 0.3607  decode.loss_ce: 0.2569  decode.acc_seg: 93.8675  aux.loss_ce: 0.1038  aux.acc_seg: 93.4989
2024/04/20 19:15:59 - mmengine - INFO - Iter(train) [ 2050/40000]  lr: 9.5424e-03  eta: 8:15:05  time: 0.7778  data_time: 0.0034  memory: 7388  loss: 0.3921  decode.loss_ce: 0.2791  decode.acc_seg: 83.1532  aux.loss_ce: 0.1130  aux.acc_seg: 83.7105
2024/04/20 19:16:38 - mmengine - INFO - Iter(train) [ 2100/40000]  lr: 9.5312e-03  eta: 8:14:22  time: 0.7785  data_time: 0.0031  memory: 7388  loss: 0.3876  decode.loss_ce: 0.2766  decode.acc_seg: 80.9089  aux.loss_ce: 0.1110  aux.acc_seg: 81.4637
2024/04/20 19:17:17 - mmengine - INFO - Iter(train) [ 2150/40000]  lr: 9.5200e-03  eta: 8:13:40  time: 0.7788  data_time: 0.0033  memory: 7388  loss: 0.3758  decode.loss_ce: 0.2651  decode.acc_seg: 94.6504  aux.loss_ce: 0.1107  aux.acc_seg: 94.3848
2024/04/20 19:17:56 - mmengine - INFO - Iter(train) [ 2200/40000]  lr: 9.5088e-03  eta: 8:12:57  time: 0.7781  data_time: 0.0036  memory: 7388  loss: 0.4106  decode.loss_ce: 0.2903  decode.acc_seg: 83.1815  aux.loss_ce: 0.1202  aux.acc_seg: 82.6841
2024/04/20 19:18:35 - mmengine - INFO - Iter(train) [ 2250/40000]  lr: 9.4976e-03  eta: 8:12:15  time: 0.7791  data_time: 0.0034  memory: 7388  loss: 0.3625  decode.loss_ce: 0.2564  decode.acc_seg: 93.9494  aux.loss_ce: 0.1061  aux.acc_seg: 94.1901
2024/04/20 19:19:14 - mmengine - INFO - Iter(train) [ 2300/40000]  lr: 9.4864e-03  eta: 8:11:33  time: 0.7779  data_time: 0.0033  memory: 7388  loss: 0.4395  decode.loss_ce: 0.3163  decode.acc_seg: 81.8581  aux.loss_ce: 0.1232  aux.acc_seg: 82.3216
2024/04/20 19:19:53 - mmengine - INFO - Iter(train) [ 2350/40000]  lr: 9.4752e-03  eta: 8:10:51  time: 0.7778  data_time: 0.0033  memory: 7388  loss: 0.3707  decode.loss_ce: 0.2627  decode.acc_seg: 87.2918  aux.loss_ce: 0.1080  aux.acc_seg: 86.6668
2024/04/20 19:20:32 - mmengine - INFO - Iter(train) [ 2400/40000]  lr: 9.4640e-03  eta: 8:10:10  time: 0.7786  data_time: 0.0034  memory: 7388  loss: 0.3505  decode.loss_ce: 0.2478  decode.acc_seg: 92.7690  aux.loss_ce: 0.1027  aux.acc_seg: 92.7849
2024/04/20 19:21:11 - mmengine - INFO - Iter(train) [ 2450/40000]  lr: 9.4528e-03  eta: 8:09:28  time: 0.7788  data_time: 0.0035  memory: 7388  loss: 0.3522  decode.loss_ce: 0.2497  decode.acc_seg: 88.3342  aux.loss_ce: 0.1025  aux.acc_seg: 88.4502
2024/04/20 19:21:50 - mmengine - INFO - Iter(train) [ 2500/40000]  lr: 9.4416e-03  eta: 8:08:46  time: 0.7769  data_time: 0.0033  memory: 7388  loss: 0.3728  decode.loss_ce: 0.2638  decode.acc_seg: 89.1527  aux.loss_ce: 0.1090  aux.acc_seg: 89.0064
2024/04/20 19:22:29 - mmengine - INFO - Iter(train) [ 2550/40000]  lr: 9.4303e-03  eta: 8:08:04  time: 0.7776  data_time: 0.0033  memory: 7388  loss: 0.3264  decode.loss_ce: 0.2311  decode.acc_seg: 90.0810  aux.loss_ce: 0.0953  aux.acc_seg: 89.6715
2024/04/20 19:23:08 - mmengine - INFO - Iter(train) [ 2600/40000]  lr: 9.4191e-03  eta: 8:07:23  time: 0.7778  data_time: 0.0035  memory: 7388  loss: 0.3387  decode.loss_ce: 0.2402  decode.acc_seg: 88.2267  aux.loss_ce: 0.0984  aux.acc_seg: 88.1928
2024/04/20 19:23:47 - mmengine - INFO - Iter(train) [ 2650/40000]  lr: 9.4079e-03  eta: 8:06:41  time: 0.7794  data_time: 0.0034  memory: 7388  loss: 0.3597  decode.loss_ce: 0.2560  decode.acc_seg: 93.2797  aux.loss_ce: 0.1037  aux.acc_seg: 93.4433
2024/04/20 19:24:26 - mmengine - INFO - Iter(train) [ 2700/40000]  lr: 9.3967e-03  eta: 8:05:59  time: 0.7774  data_time: 0.0034  memory: 7388  loss: 0.3910  decode.loss_ce: 0.2767  decode.acc_seg: 85.3232  aux.loss_ce: 0.1143  aux.acc_seg: 86.0621
2024/04/20 19:25:04 - mmengine - INFO - Iter(train) [ 2750/40000]  lr: 9.3855e-03  eta: 8:05:17  time: 0.7771  data_time: 0.0033  memory: 7388  loss: 0.2881  decode.loss_ce: 0.2039  decode.acc_seg: 91.5026  aux.loss_ce: 0.0843  aux.acc_seg: 90.9291
2024/04/20 19:25:43 - mmengine - INFO - Iter(train) [ 2800/40000]  lr: 9.3743e-03  eta: 8:04:36  time: 0.7768  data_time: 0.0034  memory: 7388  loss: 0.3682  decode.loss_ce: 0.2610  decode.acc_seg: 91.1942  aux.loss_ce: 0.1072  aux.acc_seg: 90.1315
2024/04/20 19:26:22 - mmengine - INFO - Iter(train) [ 2850/40000]  lr: 9.3630e-03  eta: 8:03:54  time: 0.7758  data_time: 0.0032  memory: 7388  loss: 0.3616  decode.loss_ce: 0.2583  decode.acc_seg: 86.6850  aux.loss_ce: 0.1034  aux.acc_seg: 87.3156
2024/04/20 19:26:24 - mmengine - INFO - Exp name: vit_deit-s16_mln_upernet_8xb2-40k-384x384_20240420_184859
2024/04/20 19:27:01 - mmengine - INFO - Iter(train) [ 2900/40000]  lr: 9.3518e-03  eta: 8:03:12  time: 0.7776  data_time: 0.0032  memory: 7388  loss: 0.3563  decode.loss_ce: 0.2529  decode.acc_seg: 84.5414  aux.loss_ce: 0.1034  aux.acc_seg: 83.9386
2024/04/20 19:27:40 - mmengine - INFO - Iter(train) [ 2950/40000]  lr: 9.3406e-03  eta: 8:02:30  time: 0.7754  data_time: 0.0033  memory: 7388  loss: 0.3831  decode.loss_ce: 0.2717  decode.acc_seg: 86.5770  aux.loss_ce: 0.1114  aux.acc_seg: 86.0198
2024/04/20 19:28:19 - mmengine - INFO - Exp name: vit_deit-s16_mln_upernet_8xb2-40k-384x384_20240420_184859
2024/04/20 19:28:19 - mmengine - INFO - Iter(train) [ 3000/40000]  lr: 9.3294e-03  eta: 8:01:48  time: 0.7785  data_time: 0.0034  memory: 7388  loss: 0.3278  decode.loss_ce: 0.2313  decode.acc_seg: 92.1341  aux.loss_ce: 0.0965  aux.acc_seg: 92.3822
2024/04/20 19:28:58 - mmengine - INFO - Iter(train) [ 3050/40000]  lr: 9.3182e-03  eta: 8:01:07  time: 0.7779  data_time: 0.0034  memory: 7388  loss: 0.3750  decode.loss_ce: 0.2650  decode.acc_seg: 89.2525  aux.loss_ce: 0.1100  aux.acc_seg: 89.0825
2024/04/20 19:29:36 - mmengine - INFO - Iter(train) [ 3100/40000]  lr: 9.3069e-03  eta: 8:00:25  time: 0.7761  data_time: 0.0036  memory: 7388  loss: 0.4322  decode.loss_ce: 0.3104  decode.acc_seg: 88.1949  aux.loss_ce: 0.1219  aux.acc_seg: 88.3505
2024/04/20 19:30:15 - mmengine - INFO - Iter(train) [ 3150/40000]  lr: 9.2957e-03  eta: 7:59:44  time: 0.7778  data_time: 0.0035  memory: 7388  loss: 0.3251  decode.loss_ce: 0.2305  decode.acc_seg: 85.1490  aux.loss_ce: 0.0946  aux.acc_seg: 85.0771
2024/04/20 19:30:54 - mmengine - INFO - Iter(train) [ 3200/40000]  lr: 9.2845e-03  eta: 7:59:03  time: 0.7775  data_time: 0.0036  memory: 7388  loss: 0.3205  decode.loss_ce: 0.2274  decode.acc_seg: 90.6731  aux.loss_ce: 0.0931  aux.acc_seg: 90.4768
2024/04/20 19:31:33 - mmengine - INFO - Iter(train) [ 3250/40000]  lr: 9.2732e-03  eta: 7:58:22  time: 0.7744  data_time: 0.0035  memory: 7388  loss: 0.2864  decode.loss_ce: 0.2018  decode.acc_seg: 87.1011  aux.loss_ce: 0.0846  aux.acc_seg: 87.5717
2024/04/20 19:32:12 - mmengine - INFO - Iter(train) [ 3300/40000]  lr: 9.2620e-03  eta: 7:57:42  time: 0.7778  data_time: 0.0036  memory: 7388  loss: 0.4093  decode.loss_ce: 0.2884  decode.acc_seg: 80.2020  aux.loss_ce: 0.1208  aux.acc_seg: 79.9668
2024/04/20 19:32:51 - mmengine - INFO - Iter(train) [ 3350/40000]  lr: 9.2508e-03  eta: 7:57:02  time: 0.7779  data_time: 0.0038  memory: 7388  loss: 0.3409  decode.loss_ce: 0.2413  decode.acc_seg: 84.4690  aux.loss_ce: 0.0997  aux.acc_seg: 83.4791
2024/04/20 19:33:30 - mmengine - INFO - Iter(train) [ 3400/40000]  lr: 9.2395e-03  eta: 7:56:21  time: 0.7769  data_time: 0.0036  memory: 7388  loss: 0.2906  decode.loss_ce: 0.2069  decode.acc_seg: 89.8808  aux.loss_ce: 0.0837  aux.acc_seg: 89.9522
2024/04/20 19:34:09 - mmengine - INFO - Iter(train) [ 3450/40000]  lr: 9.2283e-03  eta: 7:55:39  time: 0.7773  data_time: 0.0035  memory: 7388  loss: 0.3178  decode.loss_ce: 0.2234  decode.acc_seg: 86.3643  aux.loss_ce: 0.0944  aux.acc_seg: 85.6105
2024/04/20 19:34:48 - mmengine - INFO - Iter(train) [ 3500/40000]  lr: 9.2171e-03  eta: 7:54:59  time: 0.7770  data_time: 0.0034  memory: 7388  loss: 0.3280  decode.loss_ce: 0.2312  decode.acc_seg: 91.9627  aux.loss_ce: 0.0968  aux.acc_seg: 91.9808
2024/04/20 19:35:26 - mmengine - INFO - Iter(train) [ 3550/40000]  lr: 9.2058e-03  eta: 7:54:17  time: 0.7778  data_time: 0.0033  memory: 7388  loss: 0.3549  decode.loss_ce: 0.2520  decode.acc_seg: 89.6562  aux.loss_ce: 0.1029  aux.acc_seg: 89.3593
2024/04/20 19:36:05 - mmengine - INFO - Iter(train) [ 3600/40000]  lr: 9.1946e-03  eta: 7:53:36  time: 0.7767  data_time: 0.0035  memory: 7388  loss: 0.3458  decode.loss_ce: 0.2456  decode.acc_seg: 87.0269  aux.loss_ce: 0.1002  aux.acc_seg: 86.7699
2024/04/20 19:36:44 - mmengine - INFO - Iter(train) [ 3650/40000]  lr: 9.1833e-03  eta: 7:52:56  time: 0.7780  data_time: 0.0035  memory: 7388  loss: 0.3332  decode.loss_ce: 0.2356  decode.acc_seg: 86.7628  aux.loss_ce: 0.0976  aux.acc_seg: 87.3989
2024/04/20 19:37:23 - mmengine - INFO - Iter(train) [ 3700/40000]  lr: 9.1721e-03  eta: 7:52:15  time: 0.7769  data_time: 0.0035  memory: 7388  loss: 0.4173  decode.loss_ce: 0.2980  decode.acc_seg: 88.5840  aux.loss_ce: 0.1193  aux.acc_seg: 89.0819
2024/04/20 19:38:02 - mmengine - INFO - Iter(train) [ 3750/40000]  lr: 9.1608e-03  eta: 7:51:35  time: 0.7766  data_time: 0.0036  memory: 7388  loss: 0.3675  decode.loss_ce: 0.2621  decode.acc_seg: 86.9432  aux.loss_ce: 0.1053  aux.acc_seg: 86.7897
2024/04/20 19:38:41 - mmengine - INFO - Iter(train) [ 3800/40000]  lr: 9.1496e-03  eta: 7:50:55  time: 0.7768  data_time: 0.0035  memory: 7388  loss: 0.3493  decode.loss_ce: 0.2487  decode.acc_seg: 90.4978  aux.loss_ce: 0.1006  aux.acc_seg: 90.4163
2024/04/20 19:39:20 - mmengine - INFO - Iter(train) [ 3850/40000]  lr: 9.1383e-03  eta: 7:50:14  time: 0.7793  data_time: 0.0035  memory: 7388  loss: 0.3498  decode.loss_ce: 0.2476  decode.acc_seg: 89.4315  aux.loss_ce: 0.1022  aux.acc_seg: 88.6160
2024/04/20 19:39:59 - mmengine - INFO - Iter(train) [ 3900/40000]  lr: 9.1271e-03  eta: 7:49:34  time: 0.7744  data_time: 0.0035  memory: 7388  loss: 0.3643  decode.loss_ce: 0.2590  decode.acc_seg: 90.2788  aux.loss_ce: 0.1052  aux.acc_seg: 89.2295
2024/04/20 19:40:37 - mmengine - INFO - Iter(train) [ 3950/40000]  lr: 9.1158e-03  eta: 7:48:53  time: 0.7786  data_time: 0.0035  memory: 7388  loss: 0.3833  decode.loss_ce: 0.2731  decode.acc_seg: 82.6883  aux.loss_ce: 0.1102  aux.acc_seg: 83.8391
2024/04/20 19:41:16 - mmengine - INFO - Exp name: vit_deit-s16_mln_upernet_8xb2-40k-384x384_20240420_184859
2024/04/20 19:41:16 - mmengine - INFO - Iter(train) [ 4000/40000]  lr: 9.1046e-03  eta: 7:48:13  time: 0.7752  data_time: 0.0034  memory: 7388  loss: 0.3172  decode.loss_ce: 0.2249  decode.acc_seg: 90.4871  aux.loss_ce: 0.0923  aux.acc_seg: 90.0647
2024/04/20 19:41:16 - mmengine - INFO - Saving checkpoint at 4000 iterations
2024/04/20 19:41:27 - mmengine - INFO - Iter(val) [  50/1158]    eta: 0:03:23  time: 0.0130  data_time: 0.0010  memory: 2808  
2024/04/20 19:41:28 - mmengine - INFO - Iter(val) [ 100/1158]    eta: 0:01:50  time: 0.0403  data_time: 0.0008  memory: 2809  
2024/04/20 19:41:30 - mmengine - INFO - Iter(val) [ 150/1158]    eta: 0:01:17  time: 0.0257  data_time: 0.0008  memory: 2809  
2024/04/20 19:41:30 - mmengine - INFO - Iter(val) [ 200/1158]    eta: 0:00:59  time: 0.0135  data_time: 0.0008  memory: 2805  
2024/04/20 19:41:31 - mmengine - INFO - Iter(val) [ 250/1158]    eta: 0:00:47  time: 0.0129  data_time: 0.0008  memory: 2805  
2024/04/20 19:41:32 - mmengine - INFO - Iter(val) [ 300/1158]    eta: 0:00:39  time: 0.0126  data_time: 0.0007  memory: 2809  
2024/04/20 19:41:33 - mmengine - INFO - Iter(val) [ 350/1158]    eta: 0:00:33  time: 0.0129  data_time: 0.0009  memory: 783  
2024/04/20 19:41:33 - mmengine - INFO - Iter(val) [ 400/1158]    eta: 0:00:28  time: 0.0130  data_time: 0.0009  memory: 821  
2024/04/20 19:41:34 - mmengine - INFO - Iter(val) [ 450/1158]    eta: 0:00:24  time: 0.0124  data_time: 0.0006  memory: 821  
2024/04/20 19:41:35 - mmengine - INFO - Iter(val) [ 500/1158]    eta: 0:00:21  time: 0.0130  data_time: 0.0009  memory: 821  
2024/04/20 19:41:35 - mmengine - INFO - Iter(val) [ 550/1158]    eta: 0:00:18  time: 0.0137  data_time: 0.0010  memory: 821  
2024/04/20 19:41:36 - mmengine - INFO - Iter(val) [ 600/1158]    eta: 0:00:16  time: 0.0127  data_time: 0.0007  memory: 2808  
2024/04/20 19:41:37 - mmengine - INFO - Iter(val) [ 650/1158]    eta: 0:00:14  time: 0.0131  data_time: 0.0008  memory: 821  
2024/04/20 19:41:37 - mmengine - INFO - Iter(val) [ 700/1158]    eta: 0:00:12  time: 0.0142  data_time: 0.0008  memory: 2808  
2024/04/20 19:41:38 - mmengine - INFO - Iter(val) [ 750/1158]    eta: 0:00:10  time: 0.0128  data_time: 0.0007  memory: 824  
2024/04/20 19:41:39 - mmengine - INFO - Iter(val) [ 800/1158]    eta: 0:00:09  time: 0.0129  data_time: 0.0008  memory: 821  
2024/04/20 19:41:39 - mmengine - INFO - Iter(val) [ 850/1158]    eta: 0:00:07  time: 0.0135  data_time: 0.0007  memory: 810  
2024/04/20 19:41:40 - mmengine - INFO - Iter(val) [ 900/1158]    eta: 0:00:06  time: 0.0129  data_time: 0.0008  memory: 804  
2024/04/20 19:41:41 - mmengine - INFO - Iter(val) [ 950/1158]    eta: 0:00:04  time: 0.0129  data_time: 0.0008  memory: 821  
2024/04/20 19:41:41 - mmengine - INFO - Iter(val) [1000/1158]    eta: 0:00:03  time: 0.0131  data_time: 0.0007  memory: 821  
2024/04/20 19:41:42 - mmengine - INFO - Iter(val) [1050/1158]    eta: 0:00:02  time: 0.0127  data_time: 0.0008  memory: 821  
2024/04/20 19:41:43 - mmengine - INFO - Iter(val) [1100/1158]    eta: 0:00:01  time: 0.0126  data_time: 0.0006  memory: 824  
2024/04/20 19:41:43 - mmengine - INFO - Iter(val) [1150/1158]    eta: 0:00:00  time: 0.0129  data_time: 0.0007  memory: 823  
2024/04/20 19:41:43 - mmengine - INFO - per class results:
2024/04/20 19:41:43 - mmengine - INFO - 
+-----------------------------------------+-------+-------+-------+
|                  Class                  |  IoU  |  Acc  |  Dice |
+-----------------------------------------+-------+-------+-------+
|                background               |  0.0  |  nan  |  0.0  |
|              shirt, blouse              |  7.75 |  8.88 | 14.39 |
|         top, t-shirt, sweatshirt        | 41.01 | 59.42 | 58.17 |
|                 sweater                 | 15.22 | 32.81 | 26.41 |
|                 cardigan                |  0.0  |  0.0  |  0.0  |
|                  jacket                 |  9.29 | 10.01 |  17.0 |
|                   vest                  |  0.0  |  0.0  |  0.0  |
|                  pants                  | 49.82 | 64.32 | 66.51 |
|                  shorts                 | 21.42 |  23.0 | 35.28 |
|                  skirt                  | 30.62 | 38.61 | 46.89 |
|                   coat                  |  12.4 | 14.23 | 22.07 |
|                  dress                  | 57.88 | 78.21 | 73.32 |
|                 jumpsuit                |  0.0  |  0.0  |  0.0  |
|                   cape                  |  0.0  |  0.0  |  0.0  |
|                 glasses                 |  0.0  |  0.0  |  0.0  |
|                   hat                   |  7.37 |  7.48 | 13.73 |
| headband, head covering, hair accessory |  0.0  |  0.0  |  0.0  |
|                   tie                   |  0.0  |  0.0  |  0.0  |
|                  glove                  |  0.0  |  0.0  |  0.0  |
|                  watch                  |  0.0  |  0.0  |  0.0  |
|                   belt                  |  0.0  |  0.0  |  0.0  |
|                leg warmer               |  0.0  |  0.0  |  0.0  |
|            tights, stockings            | 10.92 | 13.08 | 19.69 |
|                   sock                  |  0.0  |  0.0  |  0.0  |
|                   shoe                  | 25.93 | 27.83 | 41.18 |
|               bag, wallet               | 14.64 | 16.34 | 25.54 |
|                  scarf                  |  0.22 |  0.23 |  0.45 |
|                 umbrella                |  0.0  |  0.0  |  0.0  |
|                   hood                  |  0.0  |  0.0  |  0.0  |
|                  collar                 |  2.96 |  3.14 |  5.74 |
|                  lapel                  | 13.58 | 17.68 | 23.91 |
|                epaulette                |  0.0  |  0.0  |  0.0  |
|                  sleeve                 | 37.25 | 52.12 | 54.28 |
|                  pocket                 |  0.04 |  0.04 |  0.08 |
|                 neckline                |  1.85 |  1.91 |  3.63 |
|                  buckle                 |  0.0  |  0.0  |  0.0  |
|                  zipper                 |  0.0  |  0.0  |  0.0  |
|                 applique                |  0.0  |  0.0  |  0.0  |
|                   bead                  |  0.0  |  0.0  |  0.0  |
|                   bow                   |  0.0  |  0.0  |  0.0  |
|                  flower                 |  0.0  |  0.0  |  0.0  |
|                  fringe                 |  0.0  |  0.0  |  0.0  |
|                  ribbon                 |  0.0  |  0.0  |  0.0  |
|                  rivet                  |  0.0  |  0.0  |  0.0  |
|                  ruffle                 |  0.0  |  0.0  |  0.0  |
|                  sequin                 |  0.0  |  0.0  |  0.0  |
|                  tassel                 |  0.0  |  0.0  |  0.0  |
+-----------------------------------------+-------+-------+-------+
2024/04/20 19:41:43 - mmengine - INFO - Iter(val) [1158/1158]    aAcc: 48.8200  mIoU: 7.6600  mAcc: 10.2000  mDice: 11.6700  data_time: 0.0067  time: 0.0219
2024/04/20 19:45:47 - mmengine - INFO - Iter(train) [ 4050/40000]  lr: 9.0933e-03  eta: 8:17:54  time: 4.8166  data_time: 0.0037  memory: 7372  loss: 0.3620  decode.loss_ce: 0.2561  decode.acc_seg: 88.4432  aux.loss_ce: 0.1058  aux.acc_seg: 88.2683
2024/04/20 19:49:51 - mmengine - INFO - Iter(train) [ 4100/40000]  lr: 9.0821e-03  eta: 8:46:40  time: 4.8418  data_time: 0.0037  memory: 7367  loss: 0.3627  decode.loss_ce: 0.2563  decode.acc_seg: 86.1934  aux.loss_ce: 0.1064  aux.acc_seg: 85.8026
2024/04/20 19:53:54 - mmengine - INFO - Iter(train) [ 4150/40000]  lr: 9.0708e-03  eta: 9:14:34  time: 4.8326  data_time: 0.0040  memory: 7367  loss: 0.4029  decode.loss_ce: 0.2853  decode.acc_seg: 90.9086  aux.loss_ce: 0.1176  aux.acc_seg: 90.6933
2024/04/20 19:57:57 - mmengine - INFO - Iter(train) [ 4200/40000]  lr: 9.0595e-03  eta: 9:41:42  time: 4.9025  data_time: 0.0038  memory: 7367  loss: 0.3461  decode.loss_ce: 0.2444  decode.acc_seg: 92.1264  aux.loss_ce: 0.1017  aux.acc_seg: 91.5534
2024/04/20 20:01:59 - mmengine - INFO - Iter(train) [ 4250/40000]  lr: 9.0483e-03  eta: 10:08:01  time: 4.8060  data_time: 0.0039  memory: 7367  loss: 0.3799  decode.loss_ce: 0.2710  decode.acc_seg: 88.0548  aux.loss_ce: 0.1089  aux.acc_seg: 88.0643
2024/04/20 20:06:03 - mmengine - INFO - Iter(train) [ 4300/40000]  lr: 9.0370e-03  eta: 10:33:50  time: 4.8452  data_time: 0.0036  memory: 7367  loss: 0.3310  decode.loss_ce: 0.2353  decode.acc_seg: 91.7853  aux.loss_ce: 0.0957  aux.acc_seg: 91.8001
2024/04/20 20:10:06 - mmengine - INFO - Iter(train) [ 4350/40000]  lr: 9.0257e-03  eta: 10:58:51  time: 4.8450  data_time: 0.0037  memory: 7367  loss: 0.3913  decode.loss_ce: 0.2785  decode.acc_seg: 89.2693  aux.loss_ce: 0.1128  aux.acc_seg: 89.0287
2024/04/20 20:14:10 - mmengine - INFO - Iter(train) [ 4400/40000]  lr: 9.0145e-03  eta: 11:23:21  time: 4.8954  data_time: 0.0038  memory: 7367  loss: 0.4162  decode.loss_ce: 0.2957  decode.acc_seg: 87.8087  aux.loss_ce: 0.1205  aux.acc_seg: 87.7147
2024/04/20 20:18:12 - mmengine - INFO - Iter(train) [ 4450/40000]  lr: 9.0032e-03  eta: 11:47:02  time: 4.8929  data_time: 0.0038  memory: 7367  loss: 0.2960  decode.loss_ce: 0.2105  decode.acc_seg: 91.6747  aux.loss_ce: 0.0855  aux.acc_seg: 90.7350
2024/04/20 20:22:15 - mmengine - INFO - Iter(train) [ 4500/40000]  lr: 8.9919e-03  eta: 12:10:10  time: 4.8858  data_time: 0.0035  memory: 7367  loss: 0.3493  decode.loss_ce: 0.2481  decode.acc_seg: 87.8292  aux.loss_ce: 0.1012  aux.acc_seg: 87.6638
2024/04/20 20:26:19 - mmengine - INFO - Iter(train) [ 4550/40000]  lr: 8.9807e-03  eta: 12:32:44  time: 4.8616  data_time: 0.0037  memory: 7367  loss: 0.4160  decode.loss_ce: 0.2945  decode.acc_seg: 86.2946  aux.loss_ce: 0.1215  aux.acc_seg: 86.3480
2024/04/20 20:30:22 - mmengine - INFO - Iter(train) [ 4600/40000]  lr: 8.9694e-03  eta: 12:54:43  time: 4.8543  data_time: 0.0042  memory: 7367  loss: 0.3708  decode.loss_ce: 0.2618  decode.acc_seg: 90.8377  aux.loss_ce: 0.1089  aux.acc_seg: 90.1498
2024/04/20 20:34:25 - mmengine - INFO - Iter(train) [ 4650/40000]  lr: 8.9581e-03  eta: 13:16:07  time: 4.8216  data_time: 0.0036  memory: 7367  loss: 0.3392  decode.loss_ce: 0.2400  decode.acc_seg: 88.9685  aux.loss_ce: 0.0991  aux.acc_seg: 88.9396
2024/04/20 20:38:28 - mmengine - INFO - Iter(train) [ 4700/40000]  lr: 8.9468e-03  eta: 13:36:55  time: 4.8445  data_time: 0.0037  memory: 7367  loss: 0.3181  decode.loss_ce: 0.2253  decode.acc_seg: 88.3169  aux.loss_ce: 0.0928  aux.acc_seg: 87.4687
2024/04/20 20:42:31 - mmengine - INFO - Iter(train) [ 4750/40000]  lr: 8.9356e-03  eta: 13:57:16  time: 4.8667  data_time: 0.0036  memory: 7367  loss: 0.4308  decode.loss_ce: 0.3059  decode.acc_seg: 75.4663  aux.loss_ce: 0.1249  aux.acc_seg: 75.6045
2024/04/20 20:46:35 - mmengine - INFO - Iter(train) [ 4800/40000]  lr: 8.9243e-03  eta: 14:17:07  time: 4.8823  data_time: 0.0037  memory: 7367  loss: 0.2981  decode.loss_ce: 0.2105  decode.acc_seg: 90.1387  aux.loss_ce: 0.0876  aux.acc_seg: 90.2258
2024/04/20 20:50:39 - mmengine - INFO - Iter(train) [ 4850/40000]  lr: 8.9130e-03  eta: 14:36:34  time: 4.9009  data_time: 0.0038  memory: 7367  loss: 0.3111  decode.loss_ce: 0.2203  decode.acc_seg: 89.9255  aux.loss_ce: 0.0908  aux.acc_seg: 88.9837
2024/04/20 20:54:41 - mmengine - INFO - Iter(train) [ 4900/40000]  lr: 8.9017e-03  eta: 14:55:19  time: 4.8317  data_time: 0.0035  memory: 7367  loss: 0.3915  decode.loss_ce: 0.2764  decode.acc_seg: 82.6846  aux.loss_ce: 0.1150  aux.acc_seg: 82.4656
2024/04/20 20:58:45 - mmengine - INFO - Iter(train) [ 4950/40000]  lr: 8.8904e-03  eta: 15:13:46  time: 4.8272  data_time: 0.0037  memory: 7367  loss: 0.3396  decode.loss_ce: 0.2411  decode.acc_seg: 94.8757  aux.loss_ce: 0.0985  aux.acc_seg: 94.3820
2024/04/20 21:02:48 - mmengine - INFO - Exp name: vit_deit-s16_mln_upernet_8xb2-40k-384x384_20240420_184859
2024/04/20 21:02:48 - mmengine - INFO - Iter(train) [ 5000/40000]  lr: 8.8791e-03  eta: 15:31:44  time: 4.8307  data_time: 0.0036  memory: 7367  loss: 0.3716  decode.loss_ce: 0.2629  decode.acc_seg: 91.1704  aux.loss_ce: 0.1087  aux.acc_seg: 91.6490
2024/04/20 21:06:50 - mmengine - INFO - Iter(train) [ 5050/40000]  lr: 8.8679e-03  eta: 15:49:04  time: 4.8164  data_time: 0.0042  memory: 7367  loss: 0.3690  decode.loss_ce: 0.2619  decode.acc_seg: 88.3879  aux.loss_ce: 0.1071  aux.acc_seg: 88.4457
2024/04/20 21:10:52 - mmengine - INFO - Iter(train) [ 5100/40000]  lr: 8.8566e-03  eta: 16:06:04  time: 4.8590  data_time: 0.0036  memory: 7367  loss: 0.3103  decode.loss_ce: 0.2189  decode.acc_seg: 92.7731  aux.loss_ce: 0.0914  aux.acc_seg: 91.9198
2024/04/20 21:14:55 - mmengine - INFO - Iter(train) [ 5150/40000]  lr: 8.8453e-03  eta: 16:22:41  time: 4.8930  data_time: 0.0037  memory: 7367  loss: 0.3367  decode.loss_ce: 0.2394  decode.acc_seg: 89.2591  aux.loss_ce: 0.0974  aux.acc_seg: 89.8073
2024/04/20 21:18:58 - mmengine - INFO - Iter(train) [ 5200/40000]  lr: 8.8340e-03  eta: 16:38:57  time: 4.8624  data_time: 0.0037  memory: 7367  loss: 0.3397  decode.loss_ce: 0.2397  decode.acc_seg: 89.9764  aux.loss_ce: 0.1001  aux.acc_seg: 90.4079
2024/04/20 21:23:01 - mmengine - INFO - Iter(train) [ 5250/40000]  lr: 8.8227e-03  eta: 16:54:49  time: 4.7903  data_time: 0.0036  memory: 7367  loss: 0.3097  decode.loss_ce: 0.2189  decode.acc_seg: 93.4222  aux.loss_ce: 0.0908  aux.acc_seg: 93.2365
2024/04/20 21:27:03 - mmengine - INFO - Iter(train) [ 5300/40000]  lr: 8.8114e-03  eta: 17:10:10  time: 4.8046  data_time: 0.0037  memory: 7367  loss: 0.3656  decode.loss_ce: 0.2584  decode.acc_seg: 83.6359  aux.loss_ce: 0.1071  aux.acc_seg: 83.6183
2024/04/20 21:31:04 - mmengine - INFO - Iter(train) [ 5350/40000]  lr: 8.8001e-03  eta: 17:25:08  time: 4.8650  data_time: 0.0035  memory: 7367  loss: 0.3301  decode.loss_ce: 0.2327  decode.acc_seg: 88.6072  aux.loss_ce: 0.0974  aux.acc_seg: 88.7893
2024/04/20 21:35:09 - mmengine - INFO - Iter(train) [ 5400/40000]  lr: 8.7888e-03  eta: 17:40:04  time: 4.8455  data_time: 0.0035  memory: 7367  loss: 0.3171  decode.loss_ce: 0.2245  decode.acc_seg: 91.1018  aux.loss_ce: 0.0925  aux.acc_seg: 91.8779
2024/04/20 21:39:12 - mmengine - INFO - Iter(train) [ 5450/40000]  lr: 8.7775e-03  eta: 17:54:33  time: 4.8938  data_time: 0.0034  memory: 7367  loss: 0.3174  decode.loss_ce: 0.2259  decode.acc_seg: 90.2011  aux.loss_ce: 0.0916  aux.acc_seg: 90.4212
2024/04/20 21:43:16 - mmengine - INFO - Iter(train) [ 5500/40000]  lr: 8.7662e-03  eta: 18:08:46  time: 4.8907  data_time: 0.0036  memory: 7367  loss: 0.3466  decode.loss_ce: 0.2452  decode.acc_seg: 86.7951  aux.loss_ce: 0.1014  aux.acc_seg: 86.8364
2024/04/20 21:47:19 - mmengine - INFO - Iter(train) [ 5550/40000]  lr: 8.7549e-03  eta: 18:22:30  time: 4.8418  data_time: 0.0038  memory: 7367  loss: 0.3564  decode.loss_ce: 0.2554  decode.acc_seg: 88.9136  aux.loss_ce: 0.1011  aux.acc_seg: 88.8228
2024/04/20 21:51:23 - mmengine - INFO - Iter(train) [ 5600/40000]  lr: 8.7436e-03  eta: 18:36:01  time: 4.9058  data_time: 0.0034  memory: 7367  loss: 0.3019  decode.loss_ce: 0.2133  decode.acc_seg: 90.0231  aux.loss_ce: 0.0886  aux.acc_seg: 88.3922
2024/04/20 21:55:26 - mmengine - INFO - Iter(train) [ 5650/40000]  lr: 8.7323e-03  eta: 18:49:13  time: 4.9012  data_time: 0.0037  memory: 7367  loss: 0.3220  decode.loss_ce: 0.2292  decode.acc_seg: 85.0754  aux.loss_ce: 0.0928  aux.acc_seg: 84.9936
2024/04/20 21:59:29 - mmengine - INFO - Iter(train) [ 5700/40000]  lr: 8.7210e-03  eta: 19:02:02  time: 4.8634  data_time: 0.0035  memory: 7367  loss: 0.3586  decode.loss_ce: 0.2548  decode.acc_seg: 90.5788  aux.loss_ce: 0.1037  aux.acc_seg: 90.5993
2024/04/20 22:03:31 - mmengine - INFO - Iter(train) [ 5750/40000]  lr: 8.7096e-03  eta: 19:14:30  time: 4.8425  data_time: 0.0038  memory: 7367  loss: 0.2996  decode.loss_ce: 0.2129  decode.acc_seg: 88.4326  aux.loss_ce: 0.0866  aux.acc_seg: 87.7014
2024/04/20 22:07:34 - mmengine - INFO - Iter(train) [ 5800/40000]  lr: 8.6983e-03  eta: 19:26:42  time: 4.8602  data_time: 0.0035  memory: 7367  loss: 0.3710  decode.loss_ce: 0.2660  decode.acc_seg: 90.6089  aux.loss_ce: 0.1050  aux.acc_seg: 90.7420
2024/04/20 22:11:37 - mmengine - INFO - Iter(train) [ 5850/40000]  lr: 8.6870e-03  eta: 19:38:42  time: 4.8821  data_time: 0.0035  memory: 7367  loss: 0.3841  decode.loss_ce: 0.2719  decode.acc_seg: 87.4794  aux.loss_ce: 0.1122  aux.acc_seg: 87.3276
2024/04/20 22:15:40 - mmengine - INFO - Iter(train) [ 5900/40000]  lr: 8.6757e-03  eta: 19:50:28  time: 4.9189  data_time: 0.0038  memory: 7367  loss: 0.3283  decode.loss_ce: 0.2335  decode.acc_seg: 87.8110  aux.loss_ce: 0.0948  aux.acc_seg: 87.3278
2024/04/20 22:19:44 - mmengine - INFO - Iter(train) [ 5950/40000]  lr: 8.6644e-03  eta: 20:01:57  time: 4.9141  data_time: 0.0034  memory: 7367  loss: 0.2771  decode.loss_ce: 0.1964  decode.acc_seg: 91.3301  aux.loss_ce: 0.0807  aux.acc_seg: 91.0517
2024/04/20 22:23:47 - mmengine - INFO - Exp name: vit_deit-s16_mln_upernet_8xb2-40k-384x384_20240420_184859
2024/04/20 22:23:47 - mmengine - INFO - Iter(train) [ 6000/40000]  lr: 8.6531e-03  eta: 20:13:11  time: 4.8829  data_time: 0.0035  memory: 7367  loss: 0.3064  decode.loss_ce: 0.2182  decode.acc_seg: 89.9385  aux.loss_ce: 0.0882  aux.acc_seg: 89.6426
2024/04/20 22:27:50 - mmengine - INFO - Iter(train) [ 6050/40000]  lr: 8.6417e-03  eta: 20:24:03  time: 4.8478  data_time: 0.0037  memory: 7367  loss: 0.3905  decode.loss_ce: 0.2773  decode.acc_seg: 89.8801  aux.loss_ce: 0.1132  aux.acc_seg: 90.6245
2024/04/20 22:31:52 - mmengine - INFO - Iter(train) [ 6100/40000]  lr: 8.6304e-03  eta: 20:34:38  time: 4.8698  data_time: 0.0038  memory: 7367  loss: 0.3576  decode.loss_ce: 0.2521  decode.acc_seg: 88.6361  aux.loss_ce: 0.1056  aux.acc_seg: 88.8573
2024/04/20 22:35:54 - mmengine - INFO - Iter(train) [ 6150/40000]  lr: 8.6191e-03  eta: 20:44:59  time: 4.8068  data_time: 0.0036  memory: 7367  loss: 0.3884  decode.loss_ce: 0.2743  decode.acc_seg: 88.8386  aux.loss_ce: 0.1141  aux.acc_seg: 88.8957
2024/04/20 22:39:56 - mmengine - INFO - Iter(train) [ 6200/40000]  lr: 8.6078e-03  eta: 20:55:09  time: 4.8777  data_time: 0.0036  memory: 7367  loss: 0.3148  decode.loss_ce: 0.2221  decode.acc_seg: 89.4041  aux.loss_ce: 0.0927  aux.acc_seg: 88.2640
2024/04/20 22:44:00 - mmengine - INFO - Iter(train) [ 6250/40000]  lr: 8.5964e-03  eta: 21:05:15  time: 4.9082  data_time: 0.0035  memory: 7367  loss: 0.3484  decode.loss_ce: 0.2463  decode.acc_seg: 89.6992  aux.loss_ce: 0.1021  aux.acc_seg: 89.5206
2024/04/20 22:48:04 - mmengine - INFO - Iter(train) [ 6300/40000]  lr: 8.5851e-03  eta: 21:15:05  time: 4.8597  data_time: 0.0036  memory: 7367  loss: 0.3467  decode.loss_ce: 0.2452  decode.acc_seg: 89.0982  aux.loss_ce: 0.1015  aux.acc_seg: 89.0550
2024/04/20 22:52:07 - mmengine - INFO - Iter(train) [ 6350/40000]  lr: 8.5738e-03  eta: 21:24:38  time: 4.9227  data_time: 0.0035  memory: 7367  loss: 0.3386  decode.loss_ce: 0.2402  decode.acc_seg: 89.7751  aux.loss_ce: 0.0984  aux.acc_seg: 89.0476
2024/04/20 22:56:10 - mmengine - INFO - Iter(train) [ 6400/40000]  lr: 8.5625e-03  eta: 21:33:58  time: 4.8515  data_time: 0.0034  memory: 7368  loss: 0.3063  decode.loss_ce: 0.2156  decode.acc_seg: 91.0488  aux.loss_ce: 0.0907  aux.acc_seg: 89.5926
2024/04/20 23:00:13 - mmengine - INFO - Iter(train) [ 6450/40000]  lr: 8.5511e-03  eta: 21:43:06  time: 4.9003  data_time: 0.0033  memory: 7367  loss: 0.3141  decode.loss_ce: 0.2240  decode.acc_seg: 88.2826  aux.loss_ce: 0.0901  aux.acc_seg: 87.9184
2024/04/20 23:04:15 - mmengine - INFO - Iter(train) [ 6500/40000]  lr: 8.5398e-03  eta: 21:51:57  time: 4.8268  data_time: 0.0037  memory: 7367  loss: 0.3326  decode.loss_ce: 0.2344  decode.acc_seg: 86.0591  aux.loss_ce: 0.0982  aux.acc_seg: 84.5934
2024/04/20 23:08:17 - mmengine - INFO - Iter(train) [ 6550/40000]  lr: 8.5284e-03  eta: 22:00:35  time: 4.9054  data_time: 0.0034  memory: 7367  loss: 0.3476  decode.loss_ce: 0.2457  decode.acc_seg: 89.9673  aux.loss_ce: 0.1019  aux.acc_seg: 89.9481
2024/04/20 23:12:21 - mmengine - INFO - Iter(train) [ 6600/40000]  lr: 8.5171e-03  eta: 22:09:09  time: 4.8814  data_time: 0.0035  memory: 7367  loss: 0.3118  decode.loss_ce: 0.2222  decode.acc_seg: 91.9375  aux.loss_ce: 0.0896  aux.acc_seg: 91.7780
2024/04/20 23:16:24 - mmengine - INFO - Iter(train) [ 6650/40000]  lr: 8.5058e-03  eta: 22:17:29  time: 4.8962  data_time: 0.0037  memory: 7367  loss: 0.2745  decode.loss_ce: 0.1959  decode.acc_seg: 90.1342  aux.loss_ce: 0.0786  aux.acc_seg: 90.6001
2024/04/20 23:20:26 - mmengine - INFO - Iter(train) [ 6700/40000]  lr: 8.4944e-03  eta: 22:25:36  time: 4.8166  data_time: 0.0035  memory: 7367  loss: 0.3882  decode.loss_ce: 0.2783  decode.acc_seg: 85.1635  aux.loss_ce: 0.1099  aux.acc_seg: 85.6721
2024/04/20 23:24:30 - mmengine - INFO - Iter(train) [ 6750/40000]  lr: 8.4831e-03  eta: 22:33:38  time: 4.8978  data_time: 0.0038  memory: 7367  loss: 0.3461  decode.loss_ce: 0.2444  decode.acc_seg: 86.4947  aux.loss_ce: 0.1018  aux.acc_seg: 86.3077
2024/04/20 23:28:33 - mmengine - INFO - Iter(train) [ 6800/40000]  lr: 8.4717e-03  eta: 22:41:25  time: 4.8825  data_time: 0.0038  memory: 7367  loss: 0.3256  decode.loss_ce: 0.2303  decode.acc_seg: 90.4064  aux.loss_ce: 0.0953  aux.acc_seg: 90.9636
2024/04/20 23:32:36 - mmengine - INFO - Iter(train) [ 6850/40000]  lr: 8.4604e-03  eta: 22:49:06  time: 4.8567  data_time: 0.0037  memory: 7367  loss: 0.3347  decode.loss_ce: 0.2358  decode.acc_seg: 91.5383  aux.loss_ce: 0.0988  aux.acc_seg: 91.4812
2024/04/20 23:36:38 - mmengine - INFO - Iter(train) [ 6900/40000]  lr: 8.4490e-03  eta: 22:56:28  time: 4.8180  data_time: 0.0037  memory: 7367  loss: 0.3450  decode.loss_ce: 0.2448  decode.acc_seg: 89.3388  aux.loss_ce: 0.1002  aux.acc_seg: 89.6545
2024/04/20 23:40:43 - mmengine - INFO - Iter(train) [ 6950/40000]  lr: 8.4377e-03  eta: 23:03:52  time: 4.8355  data_time: 0.0040  memory: 7367  loss: 0.3507  decode.loss_ce: 0.2480  decode.acc_seg: 83.1372  aux.loss_ce: 0.1027  aux.acc_seg: 83.7714
2024/04/20 23:44:45 - mmengine - INFO - Exp name: vit_deit-s16_mln_upernet_8xb2-40k-384x384_20240420_184859
2024/04/20 23:44:45 - mmengine - INFO - Iter(train) [ 7000/40000]  lr: 8.4263e-03  eta: 23:10:57  time: 4.8443  data_time: 0.0038  memory: 7367  loss: 0.3827  decode.loss_ce: 0.2718  decode.acc_seg: 86.4685  aux.loss_ce: 0.1109  aux.acc_seg: 86.7357
2024/04/20 23:48:48 - mmengine - INFO - Iter(train) [ 7050/40000]  lr: 8.4150e-03  eta: 23:17:53  time: 4.8480  data_time: 0.0036  memory: 7367  loss: 0.3825  decode.loss_ce: 0.2699  decode.acc_seg: 85.5361  aux.loss_ce: 0.1127  aux.acc_seg: 85.8503
2024/04/20 23:52:51 - mmengine - INFO - Iter(train) [ 7100/40000]  lr: 8.4036e-03  eta: 23:24:46  time: 4.8345  data_time: 0.0037  memory: 7367  loss: 0.3078  decode.loss_ce: 0.2173  decode.acc_seg: 86.0409  aux.loss_ce: 0.0904  aux.acc_seg: 85.9257
2024/04/20 23:56:54 - mmengine - INFO - Iter(train) [ 7150/40000]  lr: 8.3923e-03  eta: 23:31:24  time: 4.8593  data_time: 0.0036  memory: 7367  loss: 0.2894  decode.loss_ce: 0.2026  decode.acc_seg: 95.2117  aux.loss_ce: 0.0867  aux.acc_seg: 94.8213
2024/04/21 00:00:56 - mmengine - INFO - Iter(train) [ 7200/40000]  lr: 8.3809e-03  eta: 23:37:49  time: 4.8416  data_time: 0.0035  memory: 7367  loss: 0.3230  decode.loss_ce: 0.2291  decode.acc_seg: 91.7938  aux.loss_ce: 0.0939  aux.acc_seg: 92.0746
2024/04/21 00:04:57 - mmengine - INFO - Iter(train) [ 7250/40000]  lr: 8.3695e-03  eta: 23:44:03  time: 4.8111  data_time: 0.0037  memory: 7367  loss: 0.2902  decode.loss_ce: 0.2067  decode.acc_seg: 86.6150  aux.loss_ce: 0.0835  aux.acc_seg: 86.6502
2024/04/21 00:09:00 - mmengine - INFO - Iter(train) [ 7300/40000]  lr: 8.3582e-03  eta: 23:50:17  time: 4.8772  data_time: 0.0034  memory: 7367  loss: 0.3523  decode.loss_ce: 0.2496  decode.acc_seg: 91.0859  aux.loss_ce: 0.1027  aux.acc_seg: 90.6825
2024/04/21 00:13:02 - mmengine - INFO - Iter(train) [ 7350/40000]  lr: 8.3468e-03  eta: 23:56:19  time: 4.8491  data_time: 0.0035  memory: 7367  loss: 0.4060  decode.loss_ce: 0.2883  decode.acc_seg: 83.9030  aux.loss_ce: 0.1177  aux.acc_seg: 83.5324
2024/04/21 00:17:05 - mmengine - INFO - Iter(train) [ 7400/40000]  lr: 8.3354e-03  eta: 1 day, 0:02:16  time: 4.8597  data_time: 0.0038  memory: 7367  loss: 0.3585  decode.loss_ce: 0.2542  decode.acc_seg: 89.4389  aux.loss_ce: 0.1044  aux.acc_seg: 88.3220
2024/04/21 00:21:07 - mmengine - INFO - Iter(train) [ 7450/40000]  lr: 8.3241e-03  eta: 1 day, 0:08:01  time: 4.8412  data_time: 0.0037  memory: 7367  loss: 0.2635  decode.loss_ce: 0.1864  decode.acc_seg: 88.3291  aux.loss_ce: 0.0771  aux.acc_seg: 88.1246
2024/04/21 00:25:11 - mmengine - INFO - Iter(train) [ 7500/40000]  lr: 8.3127e-03  eta: 1 day, 0:13:45  time: 4.8797  data_time: 0.0036  memory: 7367  loss: 0.3678  decode.loss_ce: 0.2615  decode.acc_seg: 91.9718  aux.loss_ce: 0.1063  aux.acc_seg: 92.2639
2024/04/21 00:29:15 - mmengine - INFO - Iter(train) [ 7550/40000]  lr: 8.3013e-03  eta: 1 day, 0:19:22  time: 4.9091  data_time: 0.0035  memory: 7367  loss: 0.3269  decode.loss_ce: 0.2314  decode.acc_seg: 89.2758  aux.loss_ce: 0.0955  aux.acc_seg: 89.6216
2024/04/21 00:33:19 - mmengine - INFO - Iter(train) [ 7600/40000]  lr: 8.2900e-03  eta: 1 day, 0:24:52  time: 4.8689  data_time: 0.0038  memory: 7367  loss: 0.3345  decode.loss_ce: 0.2367  decode.acc_seg: 86.9650  aux.loss_ce: 0.0978  aux.acc_seg: 86.6530
2024/04/21 00:37:23 - mmengine - INFO - Iter(train) [ 7650/40000]  lr: 8.2786e-03  eta: 1 day, 0:30:14  time: 4.8616  data_time: 0.0036  memory: 7367  loss: 0.3051  decode.loss_ce: 0.2169  decode.acc_seg: 91.2846  aux.loss_ce: 0.0882  aux.acc_seg: 91.9090
2024/04/21 00:41:25 - mmengine - INFO - Iter(train) [ 7700/40000]  lr: 8.2672e-03  eta: 1 day, 0:35:24  time: 4.8912  data_time: 0.0037  memory: 7367  loss: 0.3660  decode.loss_ce: 0.2585  decode.acc_seg: 86.1966  aux.loss_ce: 0.1075  aux.acc_seg: 85.9599
2024/04/21 00:45:29 - mmengine - INFO - Iter(train) [ 7750/40000]  lr: 8.2558e-03  eta: 1 day, 0:40:29  time: 4.8433  data_time: 0.0036  memory: 7367  loss: 0.3344  decode.loss_ce: 0.2366  decode.acc_seg: 90.7191  aux.loss_ce: 0.0978  aux.acc_seg: 88.9595
2024/04/21 00:49:33 - mmengine - INFO - Iter(train) [ 7800/40000]  lr: 8.2444e-03  eta: 1 day, 0:45:31  time: 4.8550  data_time: 0.0036  memory: 7367  loss: 0.3874  decode.loss_ce: 0.2759  decode.acc_seg: 88.4797  aux.loss_ce: 0.1115  aux.acc_seg: 88.1246
2024/04/21 00:53:36 - mmengine - INFO - Iter(train) [ 7850/40000]  lr: 8.2331e-03  eta: 1 day, 0:50:21  time: 4.8309  data_time: 0.0037  memory: 7367  loss: 0.3120  decode.loss_ce: 0.2196  decode.acc_seg: 85.0284  aux.loss_ce: 0.0924  aux.acc_seg: 84.2455
