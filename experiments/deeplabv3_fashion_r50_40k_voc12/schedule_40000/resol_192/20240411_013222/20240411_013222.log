2024/04/11 01:32:22 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 0
    GPU 0: NVIDIA GeForce RTX 4070 Laptop GPU
    CUDA_HOME: /usr/lib/cuda
    NVCC: Not Available
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 1.12.0+cu113
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.13.0+cu113
    OpenCV: 4.9.0
    MMEngine: 0.10.3

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 0
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2024/04/11 01:32:22 - mmengine - INFO - Config:
cfg = dict(
    crop_size=(
        192,
        192,
    ),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    data_root='../datasets/fashion/',
    dataset_type='FashionBG',
    default_hooks=dict(
        checkpoint=dict(by_epoch=False, interval=4000, type='CheckpointHook'),
        logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
        param_scheduler=dict(type='ParamSchedulerHook'),
        sampler_seed=dict(type='DistSamplerSeedHook'),
        timer=dict(type='IterTimerHook'),
        visualization=dict(type='SegVisualizationHook')),
    default_scope='mmseg',
    env_cfg=dict(
        cudnn_benchmark=True,
        dist_cfg=dict(backend='nccl'),
        mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0)),
    img_ratios=[
        0.5,
        0.75,
        1.0,
        1.25,
        1.5,
        1.75,
    ],
    load_from=
    'checkpoints/deeplabv3plus_r50-d8_512x512_20k_voc12aug_20200617_102323-aad58ef1.pth',
    log_level='INFO',
    log_processor=dict(by_epoch=False),
    model=dict(
        auxiliary_head=dict(
            align_corners=False,
            channels=256,
            concat_input=False,
            dropout_ratio=0.1,
            in_channels=1024,
            in_index=2,
            loss_decode=dict(
                loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
            norm_cfg=dict(requires_grad=True, type='BN'),
            num_classes=47,
            num_convs=1,
            type='FCNHead'),
        backbone=dict(
            contract_dilation=True,
            depth=50,
            dilations=(
                1,
                1,
                2,
                4,
            ),
            norm_cfg=dict(requires_grad=True, type='BN'),
            norm_eval=False,
            num_stages=4,
            out_indices=(
                0,
                1,
                2,
                3,
            ),
            strides=(
                1,
                2,
                1,
                1,
            ),
            style='pytorch',
            type='ResNetV1c'),
        data_preprocessor=dict(
            bgr_to_rgb=True,
            mean=[
                135.43535295,
                125.5206132,
                122.8418554,
            ],
            pad_val=0,
            seg_pad_val=255,
            size=(
                192,
                192,
            ),
            std=[
                64.70508792,
                63.73913779,
                62.8355091,
            ],
            type='SegDataPreProcessor'),
        decode_head=dict(
            align_corners=False,
            c1_channels=48,
            c1_in_channels=256,
            channels=512,
            dilations=(
                1,
                12,
                24,
                36,
            ),
            dropout_ratio=0.1,
            in_channels=2048,
            in_index=3,
            loss_decode=dict(
                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
            norm_cfg=dict(requires_grad=True, type='BN'),
            num_classes=47,
            type='DepthwiseSeparableASPPHead'),
        pretrained='open-mmlab://resnet50_v1c',
        test_cfg=dict(mode='whole'),
        train_cfg=dict(),
        type='EncoderDecoder'),
    norm_cfg=dict(requires_grad=True, type='BN'),
    optim_wrapper=dict(
        clip_grad=None,
        optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
        type='OptimWrapper'),
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    param_scheduler=[
        dict(
            begin=0,
            by_epoch=False,
            end=40000,
            eta_min=0.0001,
            power=0.9,
            type='PolyLR'),
    ],
    randomness=dict(seed=0),
    resume=False,
    test_cfg=dict(type='TestLoop'),
    test_dataloader=dict(
        batch_size=1,
        dataset=dict(
            ann_file=0,
            data_prefix=dict(
                img_path='images/val2020', seg_map_path='annotations/val2020'),
            data_root='../datasets/fashion/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(keep_ratio=True, scale=(
                    320,
                    240,
                ), type='Resize'),
                dict(type='LoadAnnotations'),
                dict(type='PackSegInputs'),
            ],
            type='FashionBG'),
        num_workers=4,
        persistent_workers=True,
        sampler=dict(shuffle=False, type='DefaultSampler')),
    test_evaluator=dict(
        classwise=True,
        ignore_index=0,
        iou_metrics=[
            'mIoU',
            'mDice',
        ],
        type='IoUMetric'),
    test_pipeline=[
        dict(type='LoadImageFromFile'),
        dict(keep_ratio=True, scale=(
            320,
            240,
        ), type='Resize'),
        dict(type='LoadAnnotations'),
        dict(type='PackSegInputs'),
    ],
    train_cfg=dict(
        max_iters=40000, type='IterBasedTrainLoop', val_interval=4000),
    train_dataloader=dict(
        batch_size=16,
        dataset=dict(
            ann_file=0,
            data_prefix=dict(
                img_path='images/train2020',
                seg_map_path='annotations/train2020'),
            data_root='../datasets/fashion/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations'),
                dict(
                    transforms=[
                        dict(limit=20, p=0.5, type='Rotate'),
                        dict(
                            p=0.5,
                            rotate_limit=20,
                            scale_limit=0.1,
                            shift_limit=0.1,
                            type='ShiftScaleRotate'),
                    ],
                    type='Albu'),
                dict(
                    keep_ratio=True,
                    ratio_range=(
                        0.5,
                        2.0,
                    ),
                    scale=(
                        320,
                        240,
                    ),
                    type='RandomResize'),
                dict(
                    cat_max_ratio=0.75,
                    crop_size=(
                        192,
                        192,
                    ),
                    type='RandomCrop'),
                dict(prob=0.5, type='RandomFlip'),
                dict(type='PackSegInputs'),
            ],
            type='FashionBG'),
        num_workers=4,
        persistent_workers=True,
        sampler=dict(shuffle=True, type='InfiniteSampler')),
    train_pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            transforms=[
                dict(limit=20, p=0.5, type='Rotate'),
                dict(
                    p=0.5,
                    rotate_limit=20,
                    scale_limit=0.1,
                    shift_limit=0.1,
                    type='ShiftScaleRotate'),
            ],
            type='Albu'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                320,
                240,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            192,
            192,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PackSegInputs'),
    ],
    tta_model=dict(type='SegTTAModel'),
    tta_pipeline=[
        dict(backend_args=None, type='LoadImageFromFile'),
        dict(
            transforms=[
                [
                    dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                    dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                    dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                    dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                    dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                    dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
                ],
                [
                    dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                    dict(direction='horizontal', prob=1.0, type='RandomFlip'),
                ],
                [
                    dict(type='LoadAnnotations'),
                ],
                [
                    dict(type='PackSegInputs'),
                ],
            ],
            type='TestTimeAug'),
    ],
    val_cfg=dict(type='ValLoop'),
    val_dataloader=dict(
        batch_size=1,
        dataset=dict(
            ann_file=0,
            data_prefix=dict(
                img_path='images/val2020', seg_map_path='annotations/val2020'),
            data_root='../datasets/fashion/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(keep_ratio=True, scale=(
                    320,
                    240,
                ), type='Resize'),
                dict(type='LoadAnnotations'),
                dict(type='PackSegInputs'),
            ],
            type='FashionBG'),
        num_workers=4,
        persistent_workers=True,
        sampler=dict(shuffle=False, type='DefaultSampler')),
    val_evaluator=dict(
        classwise=True,
        ignore_index=0,
        iou_metrics=[
            'mIoU',
            'mDice',
        ],
        type='IoUMetric'),
    vis_backends=[
        dict(type='LocalVisBackend'),
    ],
    visualizer=dict(
        name='visualizer',
        type='SegLocalVisualizer',
        vis_backends=[
            dict(type='LocalVisBackend'),
        ]),
    work_dir='./work_dirs/tutorial')
crop_size = (
    192,
    192,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        135.43535295,
        125.5206132,
        122.8418554,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        64.70508792,
        63.73913779,
        62.8355091,
    ],
    type='SegDataPreProcessor')
data_root = '../datasets/fashion/'
dataset_type = 'FashionBG'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=4000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
load_from = 'checkpoints/deeplabv3plus_r50-d8_512x512_20k_voc12aug_20200617_102323-aad58ef1.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=1024,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='BN'),
        num_classes=47,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        contract_dilation=True,
        depth=50,
        dilations=(
            1,
            1,
            2,
            4,
        ),
        norm_cfg=dict(requires_grad=True, type='BN'),
        norm_eval=False,
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        strides=(
            1,
            2,
            1,
            1,
        ),
        style='pytorch',
        type='ResNetV1c'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            135.43535295,
            125.5206132,
            122.8418554,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            192,
            192,
        ),
        std=[
            64.70508792,
            63.73913779,
            62.8355091,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        c1_channels=48,
        c1_in_channels=256,
        channels=512,
        dilations=(
            1,
            12,
            24,
            36,
        ),
        dropout_ratio=0.1,
        in_channels=2048,
        in_index=3,
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='BN'),
        num_classes=47,
        type='DepthwiseSeparableASPPHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
name = 'fashion_r50_40k_voc12_192x192'
norm_cfg = dict(requires_grad=True, type='BN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=40000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=0)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file=0,
        data_prefix=dict(
            img_path='images/val2020', seg_map_path='annotations/val2020'),
        data_root='../datasets/fashion/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                320,
                240,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='FashionBG'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True,
    ignore_index=0,
    iou_metrics=[
        'mIoU',
        'mDice',
    ],
    type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        320,
        240,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(max_iters=40000, type='IterBasedTrainLoop', val_interval=4000)
train_dataloader = dict(
    batch_size=16,
    dataset=dict(
        ann_file=0,
        data_prefix=dict(
            img_path='images/train2020', seg_map_path='annotations/train2020'),
        data_root='../datasets/fashion/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                transforms=[
                    dict(limit=20, p=0.5, type='Rotate'),
                    dict(
                        p=0.5,
                        rotate_limit=20,
                        scale_limit=0.1,
                        shift_limit=0.1,
                        type='ShiftScaleRotate'),
                ],
                type='Albu'),
            dict(
                keep_ratio=True,
                ratio_range=(
                    0.5,
                    2.0,
                ),
                scale=(
                    320,
                    240,
                ),
                type='RandomResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    192,
                    192,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PackSegInputs'),
        ],
        type='FashionBG'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        transforms=[
            dict(limit=20, p=0.5, type='Rotate'),
            dict(
                p=0.5,
                rotate_limit=20,
                scale_limit=0.1,
                shift_limit=0.1,
                type='ShiftScaleRotate'),
        ],
        type='Albu'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            320,
            240,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        192,
        192,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file=0,
        data_prefix=dict(
            img_path='images/val2020', seg_map_path='annotations/val2020'),
        data_root='../datasets/fashion/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                320,
                240,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='FashionBG'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    classwise=True,
    ignore_index=0,
    iou_metrics=[
        'mIoU',
        'mDice',
    ],
    type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/fashion_r50_40k_voc12_192x192/schedule_40000/resol_192'

2024/04/11 01:32:25 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2024/04/11 01:32:25 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
